{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Class 102 at Gervi-Hera-Vitr\n",
    "\n",
    "We are learning about machine learning from Google!\n",
    "\n",
    "- Here is the [Machine Learning Foundations YouTube Class](https://youtube.com/playlist?list=PLOU2XLYxmsII9mzQ-Xxug4l2o04JBrkLV&si=13sb6VTquza6cmUA) that we follow.\n",
    "- And here is the [Captain Lugaru's Assignment Miro Board](https://miro.com/app/board/uXjVL-vk0o4=/ \"Episodes Explained\")"
   ],
   "id": "4c4566e2d30852ab"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    " Episode 1: Basics of ML.\n",
    " Ok, so what is ML?:\n",
    " Machine learning is a branch of Ai that enables computer systems to learn and improve from experience without being explicitly programmed. It focuses on creating algorithms and models that can analyze data, identify patterns, and make decisions or predictions based on that data. Ml is not Like traditional programming:\n",
    " ![](resources/img/RulesDataLogic-Answers.png)"
   ],
   "id": "fbbd25d0674e0a74"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Ok, so rules + data goes into traditional programming give you answers, but with Machine learning you put in data and answers to get out perfect rules, so that later you can have the model predict the other answers much better and faster than traditional programming using these new rules, ok? well now we are going to look at how a neural network works down below:",
   "id": "63b7289987754295"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "![](resources/img/Layers.png)\n",
   "id": "3a2ad8b528b6de0"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "A group of Neurons that are side by side is called a layer, and you can have multiple layers that all communicate with each other and eventually coming up with a prediction or solution. but now that you understand the very basics of ML we will start Class 1 Coding aka the \"hello world\" of ML!:\n",
   "id": "53ec3d8ae9d9d7a3"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import keras  # imports\n",
    "import numpy as np\n",
    "\n",
    "sequentialImageProcessingModel = keras.Sequential([keras.layers.Dense(units=1, input_shape=[\n",
    "    1])])  # This line creates a machine learning model using Keras, structured as a sequence of layers. It has a single dense (fully connected) layer with 1 unit (neuron) and expects input data with one feature (dimension).\n",
    "\n",
    "sequentialImageProcessingModel.compile(optimizer='sgd',\n",
    "                                       loss='mean_squared_error')  # This line sets up the model to learn by using the Stochastic Gradient Descent (SGD) optimizer to update its weights. It uses mean squared error to measure how far predictions are from the actual values during training.\n",
    "\n",
    "xs = np.array([-1.0, 0.0, 1.0, 2.0, 3.0, 4.0], dtype=float)  # data used for x and y arrays\n",
    "ys = np.array([-3.0, -1.0, 1.0, 3.0, 5.0, 7.0], dtype=float)\n",
    "\n",
    "sequentialImageProcessingModel.fit(xs, ys,\n",
    "                                   epochs=200)  #model is fitted and trained on the x and y and is given a number of epochs\n",
    "\n",
    "outcome = sequentialImageProcessingModel.predict(np.array([4.0]))  # model predicts what an x of 4 will mean for y\n",
    "print(outcome.round())  # should predict the right answer: 7.\n"
   ],
   "id": "bdb34a8ad01b63ac",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "Now,Here is the Exercise for the episode and if you are stuck with it the answer is down below:\n",
    "https://colab.research.google.com/github/lmoroney/dlaicourse/blob/master/Exercises/Exercise%201%20-%20House%20Prices/Exercise_1_House_Prices_Question.ipynb\n"
   ],
   "id": "a08a9aaf661e7f36"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "\n",
    "import numpy as np\n",
    "import keras\n",
    "\n",
    "# Define the model: a simple Sequential model with one dense layer\n",
    "sequentialImageProcessingModel = keras.Sequential([\n",
    "    keras.layers.Dense(units=1, input_shape=[1])  # One neuron, one input feature\n",
    "])\n",
    "\n",
    "# Compile the model: specify optimizer, loss function, and metrics\n",
    "sequentialImageProcessingModel.compile(optimizer='sgd',  # Stochastic Gradient Descent optimizer\n",
    "                                       loss='mean_squared_error')  # Use mean squared error for regression tasks\n",
    "\n",
    "# Input data (xs) and output data (ys) representing a simple linear relationship\n",
    "xs = np.array([-1.0, 0.0, 1.0, 2.0, 3.0, 4.0], dtype=float)  # Example inputs\n",
    "ys = np.array([-3.0, -1.0, 1.0, 3.0, 5.0, 7.0], dtype=float)  # Corresponding outputs\n",
    "\n",
    "# Train the model\n",
    "sequentialImageProcessingModel.fit(xs, ys, epochs=500)  # Train for 500 epochs to minimize loss\n",
    "\n",
    "# Use the model to predict a value\n",
    "print(sequentialImageProcessingModel.predict(np.array([7.0])))\n",
    "# Predict the output for input 7.0\n"
   ],
   "id": "f54451ee831fbfd1",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# ToDo: This is rdd13r's example of cleaner implementation and expectation for the revisit refactoring in the future\n",
    "\n",
    "from keras import Sequential\n",
    "from keras.src.layers import Conv2D, MaxPooling2D, Flatten, Dense\n",
    "from keras.src.callbacks import Callback\n",
    "from keras.src.optimizers import RMSprop\n",
    "from keras.src.legacy.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "from zipfile import ZipFile\n",
    "from shutil import rmtree\n",
    "from os import path, remove\n",
    "\n",
    "localZipFileHappyOrSad = 'resources/data/happy-or-sad.zip'\n",
    "localZipFolderHappyOrSad = 'resources/data/happy-or-sad-data'\n",
    "\n",
    "DESIRED_ACCURACY = 0.999  # This is the accuracy we want the model to achieve before stopping training\n",
    "\n",
    "if path.exists(localZipFileHappyOrSad):\n",
    "    remove(localZipFileHappyOrSad)\n",
    "    print(f\"\\n\\nHad to remove unexpected '{localZipFileHappyOrSad}'; deleted successfully.\")\n",
    "\n",
    "if path.exists(localZipFolderHappyOrSad):\n",
    "    rmtree(localZipFolderHappyOrSad)\n",
    "    print(f\"\\n\\nHad to remove unexpected '{localZipFolderHappyOrSad}'; deleted successfully.\")\n",
    "\n",
    "# Download the dataset and save it locally\n",
    "!wget --no-check-certificate -O ./resources/data/happy-or-sad.zip 'https://storage.googleapis.com/learning-datasets/happy-or-sad.zip'\n",
    "\n",
    "# Unzip the downloaded file into a folder so we can access the images\n",
    "zipHappyOrNot = ZipFile(localZipFileHappyOrSad, 'r')  # Open the zip file\n",
    "zipHappyOrNot.extractall(localZipFolderHappyOrSad)  # Extract the contents to this folder\n",
    "zipHappyOrNot.close()  # Close the zip file\n",
    "remove(localZipFileHappyOrSad)  # Delete the zip file\n",
    "\n",
    "\n",
    "# Define a custom callback that stops training once the desired accuracy is reached\n",
    "class MyHappyCallback(Callback):  # We're subclassing the Callback class from TensorFlow\n",
    "    def on_epoch_end(self, epoch, logs=None):  # This runs at the end of every epoch\n",
    "        if logs.get('accuracy') >= DESIRED_ACCURACY:  # Check if the accuracy meets our threshold\n",
    "            print(\"\\nReached 99.9% accuracy so cancelling training!\")  # Print a message to notify us\n",
    "            self.model.stop_training = True  # Stop training if the condition is met\n",
    "\n",
    "\n",
    "class TrainingEndCallback(Callback):\n",
    "    def on_train_end(self, logs=None):\n",
    "        # Actions to perform when training ends\n",
    "        print(\"Happy and Sad model training is complete; will delete image data folder.\")\n",
    "        if path.exists(localZipFolderHappyOrSad):\n",
    "            rmtree(localZipFolderHappyOrSad)\n",
    "            print(f\"'{localZipFolderHappyOrSad}'; deleted successfully.\")\n",
    "        else:\n",
    "            print(f\"Could not find '{localZipFolderHappyOrSad}'!\")\n",
    "\n",
    "\n",
    "happyCallback = MyHappyCallback()  # Create an instance of our custom epoch end callback\n",
    "cleanupCallback = TrainingEndCallback()  # Create an instance of our custom training end callback\n",
    "\n",
    "# Create an ImageDataGenerator to load and preprocess our images\n",
    "imageDataGenerator = ImageDataGenerator(\n",
    "    rescale=1.0 / 255.0)  # Rescale image pixel values to range [0, 1] for normalization\n",
    "\n",
    "# Load images from the directory and prepare them for training\n",
    "imageTrainingGenerator = imageDataGenerator.flow_from_directory(\n",
    "    localZipFolderHappyOrSad,  # Path to the folder with training images\n",
    "    target_size=(150, 150),  # Resize all images to 150x150 pixels\n",
    "    batch_size=10,  # Load 10 images at a time for training\n",
    "    class_mode='binary'  # Weâ€™re doing binary classification (happy or sad)\n",
    ")\n",
    "\n",
    "# Define the model architecture\n",
    "sequentialImageProcessingModel = Sequential([  # Sequential lets us stack layers in order\n",
    "    Conv2D(16, (3, 3), activation='relu', input_shape=(150, 150, 3)),\n",
    "    # A convolutional layer with 16 filters, a 3x3 kernel, ReLU activation, and input size of 150x150x3 (RGB)\n",
    "\n",
    "    MaxPooling2D(2, 2),\n",
    "    # A pooling layer that reduces image size by taking the maximum value in a 2x2 window (down-sampling)\n",
    "\n",
    "    Conv2D(32, (3, 3), activation='relu'),\n",
    "    # Another convolutional layer, but now with 32 filters for extracting more complex features\n",
    "\n",
    "    MaxPooling2D(2, 2),\n",
    "    # Pooling again to further reduce the image size while keeping important features\n",
    "\n",
    "    Conv2D(64, (3, 3), activation='relu'),\n",
    "    # A third convolutional layer with 64 filters for even deeper feature extraction\n",
    "\n",
    "    MaxPooling2D(2, 2),\n",
    "    # And another pooling layer to continue down-sampling the feature maps\n",
    "\n",
    "    Flatten(),\n",
    "    # Flatten the output from the convolutional layers to prepare it for the dense layers\n",
    "\n",
    "    Dense(512, activation='relu'),\n",
    "    # A fully connected dense layer with 512 neurons and ReLU activation to learn non-linear patterns\n",
    "\n",
    "    Dense(1, activation='sigmoid')\n",
    "    # The final output layer with a single neuron and sigmoid activation, because it's binary classification\n",
    "])\n",
    "\n",
    "# Compile the model with an optimizer, loss function, and evaluation metric\n",
    "sequentialImageProcessingModel.compile(\n",
    "    loss='binary_crossentropy',  # Loss function for binary classification problems\n",
    "    optimizer=RMSprop(learning_rate=0.001),  # RMSprop optimizer with a learning rate of 0.001\n",
    "    metrics=['accuracy']  # Track accuracy as the evaluation metric during training\n",
    ")\n",
    "\n",
    "# Train the model using the prepared data\n",
    "history = sequentialImageProcessingModel.fit(\n",
    "    imageTrainingGenerator,  # The training data generator\n",
    "    steps_per_epoch=8,  # Total number of steps (batches) per epoch (80 images / batch size of 10)\n",
    "    epochs=20,  # Train for a maximum of 20 epochs\n",
    "    callbacks=[happyCallback]  # Use our custom callback to stop training when desired accuracy is reached\n",
    ")\n",
    "\n"
   ],
   "id": "a8b58e31c31344eb",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "Episode 2: Computer vision by building a neural network with TensorFlow.\n",
    "What is computer vision? Computer vision is a branch of AI that allows computers to interpret and analyze visual data like images and videos, replicating human vision capabilities. It uses techniques like machine learning and deep learning to recognize objects, detect patterns, and understand pixels. Applications include face recognition, self-driving cars, medical imaging, and augmented reality.\n",
    "When you have an image, you have to give it an id so that a computer can know which image is which but when you are doing this, you have to give it a number id instead of a string id so that there is no english bias:\n",
    "![](resources/img/ImageID.png)\n",
    "Now, here is the exercise for the Mnist fashion data set: https://colab.research.google.com/github/lmoroney/dlaicourse/blob/master/Exercises/Exercise%202%20-%20Handwriting%20Recognition/Exercise2-Question.ipynbThis\n",
    "now below is the code for a computer vision model that uses the mnist data set to have the computer figure out where to place what items into 1 of the 10 categories of clothing:"
   ],
   "id": "5c22f7f39f90c487"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "# imports tensorflow\n",
    "mnist = tf.keras.datasets.mnist\n",
    "# loading in the mnist dataset\n",
    "\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "# Loads in the training and testing images.\n",
    "\n",
    "\n",
    "x_train, x_test = x_train / 255.0, x_test / 255.0\n",
    "# normalize data value's between 1 and 0\n",
    "\n",
    "\n",
    "sequentialImageProcessingModel = tf.keras.models.Sequential([\n",
    "    # This initializes a sequential model, which is a linear stack of layers. It allows you to define a simple feed-forward neural network by adding layers one after another.\n",
    "    tf.keras.layers.Flatten(input_shape=(28, 28)),\n",
    "    #The Flatten layer reshapes the 2D input images (28x28 pixels) into a 1D array of 784 elements. This is necessary to pass the data to fully connected (dense) layers. The input_shape=(28, 28) specifies the shape of the input images.\n",
    "    tf.keras.layers.Dense(128, activation='relu'),\n",
    "    #This is a fully connected (dense) layer with 128 neurons. Each neuron is connected to all neurons in the previous layer. The activation function used is ReLU (Rectified Linear Unit), if a number is less than zero it turns to zero and otherwise the number keeps it size\n",
    "\n",
    "    tf.keras.layers.Dense(10, activation='softmax')\n",
    "    #This is another dense layer with 10 neurons, corresponding to the number of output classes (e.g., digits 0-9 if working with MNIST). The softmax activation function ensures that the outputs are probabilities that sum to 1, which is ideal for multi-class classification. sets the largest to 1 and the rest to 0.\n",
    "\n",
    "])\n",
    "\n",
    "sequentialImageProcessingModel.compile(optimizer='adam',\n",
    "                                       loss='sparse_categorical_crossentropy',\n",
    "                                       metrics=['accuracy'])\n",
    "# This compiles the model, specifying the optimizer and loss function.\n",
    "# The optimizer='adam' uses the Adam optimization algorithm, which combines the benefits of RMSProp and momentum-based gradient descent.\n",
    "# The loss='sparse_categorical_crossentropy' is used for multi-class classification tasks with integer-encoded labels.\n",
    "\n",
    "\n",
    "sequentialImageProcessingModel.fit(x_train, y_train, epochs=5)\n",
    "#This trains the model on the train_images and train_labels dataset for 5 epochs (iterations over the full dataset). During training, the model adjusts its weights to minimize the loss function.\n",
    "# Evaluate the model on test data\n",
    "test_loss, test_acc = sequentialImageProcessingModel.evaluate(x_test, y_test)\n",
    "# This evaluates the trained model on the test dataset (test_images and test_labels), returning the loss (test_loss) and accuracy (test_acc). This helps to assess how well the model generalizes to unseen data.\n",
    "\n",
    "print(f\"Test accuracy: {test_acc}\")\n",
    "# prints test accuracy\n"
   ],
   "id": "fa417e35cd320be4",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "Episode 3 & 4: Convolutions and Pooling:\n",
    "what is a convolution?\n",
    "A convolution is a filter that is used in machine learning and computer vision. With convolutions we are able to process a image down to its bare features that will match the labels. using many random values in filters we can find the best filter to match the image to the label to.\n",
    "what is pooling?: Pooling is a way to decrease the resolution of an image without actually damaging its integrity and makes it lighter for the program to handle and make it learn much faster.\n",
    "How does it work though?:\n",
    "Pooling: For every 2x2 pixels, it takes the one with the darkest value and it replaces the 4 pixels with a pixel of the darkest value.\n",
    "![](resources/img/PoolingExplained.png)\n",
    "![](resources/img/PoolingCode.png)\n",
    "Convolutions: We take 3x3 pixels from an image, then we define a 3x3 filter with specific values to multiply the images value, giving us a new image that has been filtered.\n",
    "![](resources/img/ConvolutionsExplained.png)\n",
    "![](resources/img/ConvolutionsCode.png)\n",
    "Now, there is one last lesson we are gonna-wanna-learn up in here, What looks Wrong in this code:\n",
    "![](resources/img/26x26Code.png)\n",
    "It shows that the convolutions are 26x26 rather than 28x28? You may think that his is wrong but it is actually not, as when you are doing convolutions with an image, you can only apply this filter away from the edge so it does not mess up because of the empty parts outside of the image.\n",
    "Here is the Exercise for pooling and convolutions: https://colab.research.google.com/github/lmoroney/dlaicourse/blob/master/Exercises/Exercise%203%20-%20Convolutions/Exercise%203%20-%20Question.ipynb\n",
    "\n",
    "Mnist Code improved using convolutions and pooling:\n",
    "\n"
   ],
   "id": "d977fece8d7820d1"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "# Load the MNIST dataset\n",
    "mnist = tf.keras.datasets.mnist\n",
    "(training_images, training_labels), (test_images, test_labels) = mnist.load_data()\n",
    "\n",
    "# Normalize the pixel values to the range 0-1\n",
    "training_images = training_images / 255.0\n",
    "test_images = test_images / 255.0\n",
    "\n",
    "# Reshape the data to add a channel dimension (required for Conv2D)\n",
    "training_images = training_images.reshape(-1, 28, 28, 1)\n",
    "test_images = test_images.reshape(-1, 28, 28, 1)\n",
    "\n",
    "# Define the model\n",
    "sequentialImageProcessingModel = tf.keras.models.Sequential([\n",
    "    # First convolutional layer with pooling\n",
    "    tf.keras.layers.Conv2D(32, (3, 3), activation='relu', input_shape=(28, 28, 1)),\n",
    "    tf.keras.layers.MaxPooling2D(2, 2),\n",
    "\n",
    "    # Second convolutional layer with pooling\n",
    "    tf.keras.layers.Conv2D(64, (3, 3), activation='relu'),\n",
    "    tf.keras.layers.MaxPooling2D(2, 2),\n",
    "\n",
    "    # Flatten the output\n",
    "    tf.keras.layers.Flatten(),\n",
    "\n",
    "    # Fully connected dense layer\n",
    "    tf.keras.layers.Dense(128, activation='relu'),\n",
    "\n",
    "    # Output layer with 10 classes\n",
    "    tf.keras.layers.Dense(10, activation='softmax')\n",
    "])\n",
    "\n",
    "# Compile the model\n",
    "sequentialImageProcessingModel.compile(optimizer='adam',\n",
    "                                       loss='sparse_categorical_crossentropy',\n",
    "                                       metrics=['accuracy'])\n",
    "\n",
    "# Train the model\n",
    "sequentialImageProcessingModel.fit(training_images, training_labels, epochs=5)\n",
    "\n",
    "# Evaluate the model\n",
    "test_loss, test_accuracy = sequentialImageProcessingModel.evaluate(test_images, test_labels)\n",
    "print(f\"Test accuracy: {test_accuracy}\")\n"
   ],
   "id": "7c0320ca703c1dc1",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Wow! Using Convolutions and Pooling that was a lot more accurate! But it did take a quiet longer and put a much bigger strain on my computer compared to the other one without pooling or convolutions.",
   "id": "97597554d346ace8"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "Episode 5&6: Real-world image classification using convolutional neural networks\n",
    "Ok before we build our model that deals with more complex images, we first gotta learn some new stuff:\n",
    "When we have multiple categories of images we want to store and use, how do we efficiently store all of these images into categories? simple, we create a generator:\n",
    "![](resources/img/Generator.png)\n",
    "using a generator you can have tensor flow automatically name a label based off of the directory.\n",
    "here is the Exercise for a CNN that tells the difference between a horse and a human: https://colab.research.google.com/github/lmoroney/dlaicourse/blob/master/Exercises/Exercise%204%20-%20Handling%20Complex%20Images/Exercise%204-Question.ipynb\n",
    "Now we will examine the code for a CNN that uses a generator to tell the difference between a human and a horse:\n"
   ],
   "id": "9eb360b2bf01ec82"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "\n",
    "now we will get into a even harder challenge, a cat or dog CNN, here is the dataset:\n",
    "https://www.kaggle.com/c/dogs-vs-cats/data\n",
    ",here is the exercise: https://colab.research.google.com/github/lmoroney/mlday-tokyo/blob/master/Lab6-Cats-v-Dogs.ipynb#scrollTo=7v55rWlQehzL\n",
    "and here is the answer:"
   ],
   "id": "e2d65f61115bae01"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "\n",
    "import tensorflow as tf\n",
    "# from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "# Load the dataset\n",
    "!wget --no-check-certificate \\\n",
    "\"https://storage.googleapis.com/mledu-datasets/cats_and_dogs_filtered.zip\" \\\n",
    "- O\n",
    "\"/tmp/cats_and_dogs_filtered.zip\"\n",
    "\n",
    "# Unzip the dataset\n",
    "import zipfile\n",
    "\n",
    "local_zip = '/tmp/cats_and_dogs_filtered.zip'\n",
    "zipHappyOrNot = zipfile.ZipFile(local_zip, 'r')\n",
    "zipHappyOrNot.extractall('/tmp')\n",
    "zipHappyOrNot.close()\n",
    "\n",
    "# Define paths for training and validation directories\n",
    "base_dir = '/tmp/cats_and_dogs_filtered'\n",
    "train_dir = path.join(base_dir, 'train')\n",
    "validation_dir = path.join(base_dir, 'validation')\n",
    "\n",
    "# Training and validation subdirectories for cats and dogs\n",
    "train_cats_dir = path.join(train_dir, 'cats')\n",
    "train_dogs_dir = path.join(train_dir, 'dogs')\n",
    "validation_cats_dir = path.join(validation_dir, 'cats')\n",
    "validation_dogs_dir = path.join(validation_dir, 'dogs')\n",
    "\n",
    "# Define a data generator for training and validation\n",
    "imageDataGenerator = ImageDataGenerator(rescale=1.0 / 255.0)  # Normalize pixel values to [0, 1]\n",
    "validation_datagen = ImageDataGenerator(rescale=1.0 / 255.0)\n",
    "\n",
    "# Flow training images in batches of 20 using train_datagen\n",
    "imageTrainingGenerator = imageDataGenerator.flow_from_directory(\n",
    "    train_dir,  # Training directory path\n",
    "    target_size=(150, 150),  # Resize all images to 150x150\n",
    "    batch_size=20,  # Batch size\n",
    "    class_mode='binary'  # Binary classification (cats and dogs)\n",
    ")\n",
    "\n",
    "# Flow validation images in batches of 20 using validation_datagen\n",
    "validation_generator = validation_datagen.flow_from_directory(\n",
    "    validation_dir,\n",
    "    target_size=(150, 150),\n",
    "    batch_size=20,\n",
    "    class_mode='binary'\n",
    ")\n",
    "\n",
    "# Define the CNN model\n",
    "sequentialImageProcessingModel = tf.keras.models.Sequential([\n",
    "    tf.keras.layers.Conv2D(32, (3, 3), activation='relu', input_shape=(150, 150, 3)),\n",
    "    tf.keras.layers.MaxPooling2D(2, 2),\n",
    "    tf.keras.layers.Conv2D(64, (3, 3), activation='relu'),\n",
    "    tf.keras.layers.MaxPooling2D(2, 2),\n",
    "    tf.keras.layers.Conv2D(128, (3, 3), activation='relu'),\n",
    "    tf.keras.layers.MaxPooling2D(2, 2),\n",
    "    tf.keras.layers.Flatten(),\n",
    "    tf.keras.layers.Dense(512, activation='relu'),\n",
    "    tf.keras.layers.Dense(1, activation='sigmoid')  # Single output node for binary classification\n",
    "])\n",
    "\n",
    "# Compile the model\n",
    "sequentialImageProcessingModel.compile(\n",
    "    loss='binary_crossentropy',  # Binary crossentropy for binary classification\n",
    "    optimizer=tf.keras.optimizers.RMSprop(learning_rate=0.001),  # Optimizer\n",
    "    metrics=['accuracy']  # Track accuracy during training\n",
    ")\n",
    "\n",
    "# Train the model\n",
    "history = sequentialImageProcessingModel.fit(\n",
    "    imageTrainingGenerator,\n",
    "    steps_per_epoch=100,  # Number of batches per epoch\n",
    "    epochs=15,  # Number of epochs to train\n",
    "    validation_data=validation_generator,\n",
    "    validation_steps=50  # Number of batches for validation\n",
    ")\n",
    "\n",
    "# Evaluate the model\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Plot training and validation accuracy over epochs\n",
    "acc = history.history['accuracy']\n",
    "val_acc = history.history['val_accuracy']\n",
    "loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "\n",
    "epochs = range(len(acc))\n",
    "\n",
    "plt.plot(epochs, acc, 'r', label='Training Accuracy')\n",
    "plt.plot(epochs, val_acc, 'b', label='Validation Accuracy')\n",
    "plt.title('Training and Validation Accuracy')\n",
    "plt.legend(loc=0)\n",
    "plt.show()\n",
    "\n",
    "plt.plot(epochs, loss, 'r', label='Training Loss')\n",
    "plt.plot(epochs, val_loss, 'b', label='Validation Loss')\n",
    "plt.title('Training and Validation Loss')\n",
    "plt.legend(loc=0)\n",
    "plt.show()\n"
   ],
   "id": "e85bc2e2f10220e4",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "Episodes 7: Image Augmentation and Overfitting.\n",
    "What is overfitting? Overfitting occurs when a model learns the training data too well, including its noise and specific patterns, resulting in poor generalization to new, unseen data. This happens when the model is too complex (e.g., too many parameters) for the amount of training data or lacks proper regularization.\n",
    "now what is image augmentation? Image augmentation is when we use a ImageDataGenerator to change an image into something else, this helps to stop overfitting and here is the exercise:\n",
    "https://colab.research.google.com/github/lmoroney/dlaicourse/blob/master/Course%202%20-%20Part%204%20-%20Lesson%202%20-%20Notebook%20(Cats%20v%20Dogs%20Augmentation).ipynb\n",
    "And here is the code for a CNN that uses a ImageDataGenerator:"
   ],
   "id": "5cb789343e8cd03d"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Import necessary libraries\n",
    "import zipfile  # To unzip the downloaded dataset\n",
    "import tensorflow as tf  # TensorFlow for building and training the model\n",
    "from tensorflow.keras.optimizers import RMSprop  # RMSprop optimizer for training\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator  # For preprocessing and augmenting images\n",
    "\n",
    "# Download the dataset of cats and dogs and save it to a temporary directory\n",
    "!wget --no-check-certificate \\\n",
    "https: // storage.googleapis.com / mledu - datasets / cats_and_dogs_filtered.zip \\\n",
    "          - O / tmp / cats_and_dogs_filtered.zip\n",
    "\n",
    "# Define the path to the downloaded zip file\n",
    "local_zip = '/tmp/cats_and_dogs_filtered.zip'\n",
    "\n",
    "# Extract the contents of the zip file\n",
    "zipHappyOrNot = zipfile.ZipFile(local_zip, 'r')  # Open the zip file for reading\n",
    "zipHappyOrNot.extractall('/tmp')  # Extract all files to the '/tmp' directory\n",
    "zipHappyOrNot.close()  # Close the zip file after extracting\n",
    "\n",
    "# Define the base directory for the dataset\n",
    "base_dir = '/tmp/cats_and_dogs_filtered'\n",
    "\n",
    "# Set paths to training and validation directories\n",
    "train_dir = path.join(base_dir, 'train')  # Directory containing training data\n",
    "validation_dir = path.join(base_dir, 'validation')  # Directory containing validation data\n",
    "\n",
    "# Define paths for subdirectories of training and validation data\n",
    "train_cats_dir = path.join(train_dir, 'cats')  # Training images of cats\n",
    "train_dogs_dir = path.join(train_dir, 'dogs')  # Training images of dogs\n",
    "validation_cats_dir = path.join(validation_dir, 'cats')  # Validation images of cats\n",
    "validation_dogs_dir = path.join(validation_dir, 'dogs')  # Validation images of dogs\n",
    "\n",
    "# Define the CNN model\n",
    "sequentialImageProcessingModel = tf.keras.models.Sequential([  # Sequential model allows stacking layers\n",
    "    tf.keras.layers.Conv2D(32, (3, 3), activation='relu', input_shape=(150, 150, 3)),\n",
    "    # Convolutional layer with 32 filters, 3x3 kernel size, ReLU activation, and input size of 150x150x3 (RGB images)\n",
    "    tf.keras.layers.MaxPooling2D(2, 2),  # Max pooling layer to reduce spatial dimensions\n",
    "\n",
    "    tf.keras.layers.Conv2D(64, (3, 3), activation='relu'),\n",
    "    # Second convolutional layer with 64 filters\n",
    "    tf.keras.layers.MaxPooling2D(2, 2),  # Pooling to further downsample the image\n",
    "\n",
    "    tf.keras.layers.Conv2D(128, (3, 3), activation='relu'),\n",
    "    # Third convolutional layer with 128 filters\n",
    "    tf.keras.layers.MaxPooling2D(2, 2),  # Pooling again\n",
    "\n",
    "    tf.keras.layers.Conv2D(128, (3, 3), activation='relu'),\n",
    "    # Fourth convolutional layer with 128 filters\n",
    "    tf.keras.layers.MaxPooling2D(2, 2),  # Pooling again\n",
    "\n",
    "    tf.keras.layers.Dropout(0.5),  # Dropout to reduce overfitting by randomly setting 50% of neurons to 0\n",
    "\n",
    "    tf.keras.layers.Flatten(),  # Flatten layer to convert 3D feature maps to 1D vector\n",
    "\n",
    "    tf.keras.layers.Dense(512, activation='relu'),\n",
    "    # Dense layer with 512 neurons for learning high-level features\n",
    "\n",
    "    tf.keras.layers.Dense(1, activation='sigmoid')\n",
    "    # Output layer with 1 neuron and sigmoid activation for binary classification\n",
    "])\n",
    "\n",
    "# Compile the model\n",
    "sequentialImageProcessingModel.compile(\n",
    "    loss='binary_crossentropy',  # Binary cross-entropy loss for binary classification\n",
    "    optimizer=RMSprop(learning_rate=1e-4),  # RMSprop optimizer with a learning rate of 0.0001\n",
    "    metrics=['accuracy']  # Track accuracy during training\n",
    ")\n",
    "\n",
    "# Define a data generator for training with data augmentation\n",
    "imageDataGenerator = ImageDataGenerator(\n",
    "    rescale=1.0 / 255,  # Normalize pixel values to the range [0, 1]\n",
    "    rotation_range=40,  # Randomly rotate images by up to 40 degrees\n",
    "    width_shift_range=0.2,  # Randomly shift images horizontally by up to 20% of width\n",
    "    height_shift_range=0.2,  # Randomly shift images vertically by up to 20% of height\n",
    "    shear_range=0.2,  # Apply random shearing transformations\n",
    "    zoom_range=0.2,  # Randomly zoom in/out by up to 20%\n",
    "    horizontal_flip=True,  # Randomly flip images horizontally\n",
    "    fill_mode='nearest'  # Fill any gaps created by transformations with the nearest pixel value\n",
    ")\n",
    "\n",
    "# Define a data generator for validation without augmentation\n",
    "test_datagen = ImageDataGenerator(rescale=1.0 / 255)  # Only normalize pixel values\n",
    "\n",
    "# Create a generator for training data\n",
    "imageTrainingGenerator = imageDataGenerator.flow_from_directory(\n",
    "    train_dir,  # Source directory for training images\n",
    "    target_size=(150, 150),  # Resize all images to 150x150 pixels\n",
    "    batch_size=20,  # Load images in batches of 20\n",
    "    class_mode='binary'  # Binary classification (cats or dogs)\n",
    ")\n",
    "\n",
    "# Create a generator for validation data\n",
    "validation_generator = test_datagen.flow_from_directory(\n",
    "    validation_dir,  # Source directory for validation images\n",
    "    target_size=(150, 150),  # Resize all images to 150x150 pixels\n",
    "    batch_size=20,  # Load images in batches of 20\n",
    "    class_mode='binary'  # Binary classification\n",
    ")\n",
    "\n",
    "# Train the model\n",
    "history = sequentialImageProcessingModel.fit(\n",
    "    imageTrainingGenerator,  # Training data generator\n",
    "    steps_per_epoch=100,  # Number of training batches per epoch (2000 images / 20 images per batch)\n",
    "    epochs=100,  # Train the model for 100 epochs\n",
    "    validation_data=validation_generator,  # Validation data generator\n",
    "    validation_steps=50,  # Number of validation batches per epoch (1000 images / 20 images per batch)\n",
    "    verbose=2  # Print detailed logs during training\n",
    ")\n"
   ],
   "id": "55ed5f4c8e059472",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "Episodes 8 & 9 & 10: Tokenizers and Using Sequencing API's in TensorFlow.\n",
    "When creating a program that recognizes words we Use word-based encoding and ASCII:\n",
    "Word-based encoding: for each new word in a sentence we give it a value so that the computer understands better the difference between 2 sentences.\n",
    "ASCII: a common coding format where letters and sounds are assigned a number from 0 to 255\n",
    "so we get something like this: output:{'i': 1, 'love': 2, 'my': 3, 'dog': 4, 'cat': 5}\n",
    "using this we can have it create a sentence like this: 1,2,3,5(i love my cat)\n",
    "Now here is an example in code format: https://colab.research.google.com/github/lmoroney/dlaicourse/blob/master/TensorFlow%20In%20Practice/Course%203%20-%20NLP/Course%203%20-%20Week%201%20-%20Lesson%201.ipynb#scrollTo=zaCMcjMQifQc or right here:\n"
   ],
   "id": "77d0908178e76152"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "\n",
    "# List of sentences to tokenize\n",
    "sentences = [\n",
    "    'i love my dog',\n",
    "    'I, love my cat',\n",
    "    'You love my dog!'\n",
    "]\n",
    "\n",
    "# Create a Tokenizer object with a vocabulary size limit of 100\n",
    "tokenizer = Tokenizer(num_words=100)  # num_words limits the vocab to the top 100 most frequent words\n",
    "\n",
    "# Fit the tokenizer on the sentences (build the word index)\n",
    "tokenizer.fit_on_texts(sentences)\n",
    "\n",
    "# Retrieve the word index generated by the tokenizer\n",
    "word_index = tokenizer.word_index\n",
    "\n",
    "# Print the word index\n",
    "print(word_index)\n"
   ],
   "id": "a4663716c8b0d27a",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "Now we also gotta learn something else, what is padding?\n",
    "Padding is the process of adding extra values (usually zeros) to sequences to make them all the same length. Now here is a example of a Tokenizer that uses padding: https://colab.research.google.com/github/lmoroney/dlaicourse/blob/master/TensorFlow%20In%20Practice/Course%203%20-%20NLP/Course%203%20-%20Week%201%20-%20Lesson%202.ipynb#scrollTo=ArOPfBwyZtln or right here:\n"
   ],
   "id": "9e6006641f2dad7e"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "# List of sentences to tokenize\n",
    "sentences = [\n",
    "    'I love my dog',\n",
    "    'I love my cat',\n",
    "    'You love my dog!',\n",
    "    'Do you think my dog is amazing?'\n",
    "]\n",
    "\n",
    "# Create a tokenizer with a vocabulary size of 100 and an out-of-vocabulary (OOV) token\n",
    "tokenizer = Tokenizer(num_words=100, oov_token=\"<OOV>\")\n",
    "tokenizer.fit_on_texts(sentences)  # Fit the tokenizer on the input sentences to build the word index\n",
    "\n",
    "word_index = tokenizer.word_index  # Retrieve the word index (mapping of words to integers)\n",
    "sequences = tokenizer.texts_to_sequences(sentences)  # Convert sentences into sequences of integers\n",
    "\n",
    "# Pad the sequences to a maximum length of 5 (shorter sequences are left-padded with zeros)\n",
    "padded = pad_sequences(sequences, maxlen=5)\n",
    "\n",
    "# Display the word index, sequences, and padded sequences\n",
    "print(\"\\nWord Index = \", word_index)\n",
    "print(\"\\nSequences = \", sequences)\n",
    "print(\"\\nPadded Sequences:\")\n",
    "print(padded)\n",
    "\n",
    "# Test data with new words that weren't in the original sentences\n",
    "test_data = [\n",
    "    'i really love my dog',\n",
    "    'my dog loves my manatee'\n",
    "]\n",
    "\n",
    "# Convert the test data into sequences based on the original tokenizer\n",
    "test_seq = tokenizer.texts_to_sequences(test_data)\n",
    "print(\"\\nTest Sequence = \", test_seq)\n",
    "\n",
    "# Pad the test sequences to a maximum length of 10\n",
    "padded_test_seq = pad_sequences(test_seq, maxlen=10)\n",
    "print(\"\\nPadded Test Sequence: \")\n",
    "print(padded_test_seq)\n"
   ],
   "id": "c8f60d239f85e690",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Now we got one final task, and that is to create a sarcasm detector: https://colab.research.google.com/github/lmoroney/dlaicourse/blob/master/TensorFlow%20In%20Practice/Course%203%20-%20NLP/Course%203%20-%20Week%201%20-%20Lesson%202.ipynb and here is the answer down here:\n",
   "id": "848c5d6dc9fb1f9f"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "import json\n",
    "\n",
    "# Load the dataset\n",
    "with open('sarcasm.json', 'r') as f:\n",
    "    data = json.load(f)\n",
    "\n",
    "# Extract sentences (headlines) and labels (sarcasm or not)\n",
    "sentences = [item['headline'] for item in data]\n",
    "labels = [item['is_sarcastic'] for item in data]\n",
    "\n",
    "# Tokenize the sentences\n",
    "tokenizer = Tokenizer(num_words=10000, oov_token=\"<OOV>\")\n",
    "tokenizer.fit_on_texts(sentences)\n",
    "word_index = tokenizer.word_index\n",
    "sequences = tokenizer.texts_to_sequences(sentences)\n",
    "\n",
    "# Pad the sequences\n",
    "padded = pad_sequences(sequences, padding='post', maxlen=100)\n",
    "\n",
    "# Split data into training and testing sets\n",
    "training_size = int(len(sentences) * 0.8)\n",
    "train_sentences = padded[:training_size]\n",
    "train_labels = labels[:training_size]\n",
    "test_sentences = padded[training_size:]\n",
    "test_labels = labels[training_size:]\n",
    "\n",
    "# Build the model\n",
    "sequentialImageProcessingModel = tf.keras.Sequential([\n",
    "    tf.keras.layers.Embedding(10000, 16, input_length=100),  # Embedding layer for text input\n",
    "    tf.keras.layers.GlobalAveragePooling1D(),  # Reduces dimensions after embedding\n",
    "    tf.keras.layers.Dense(24, activation='relu'),  # Fully connected hidden layer\n",
    "    tf.keras.layers.Dense(1, activation='sigmoid')  # Output layer for binary classification\n",
    "])\n",
    "\n",
    "# Compile the model\n",
    "sequentialImageProcessingModel.compile(optimizer='adam',\n",
    "                                       loss='binary_crossentropy',\n",
    "                                       metrics=['accuracy'])\n",
    "\n",
    "# Train the model\n",
    "history = sequentialImageProcessingModel.fit(\n",
    "    train_sentences, train_labels,\n",
    "    epochs=10,\n",
    "    validation_data=(test_sentences, test_labels),\n",
    "    verbose=2\n",
    ")\n",
    "\n",
    "# Evaluate the model on test data\n",
    "test_loss, test_accuracy = sequentialImageProcessingModel.evaluate(test_sentences, test_labels, verbose=2)\n",
    "print(f\"Test Accuracy: {test_accuracy}\")\n",
    "\n",
    "# Test with new sentences\n",
    "new_sentences = [\"The weather is amazing today!\", \"Oh great, another Monday.\"]\n",
    "new_sequences = tokenizer.texts_to_sequences(new_sentences)\n",
    "new_padded = pad_sequences(new_sequences, padding='post', maxlen=100)\n",
    "predictions = sequentialImageProcessingModel.predict(new_padded)\n",
    "\n",
    "# Display predictions\n",
    "for i, sentence in enumerate(new_sentences):\n",
    "    print(f\"'{sentence}' -> Sarcasm score: {predictions[i][0]:.2f}\")\n"
   ],
   "id": "ede3b15a355b2902",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
