{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "s# Class 102 at Gervi-Hera-Vitr\n",
    "\n",
    "We are learning about machine learning from Google!\n",
    "\n",
    "- Here is the [Machine Learning Foundations YouTube Class](https://youtube.com/playlist?list=PLOU2XLYxmsII9mzQ-Xxug4l2o04JBrkLV&si=13sb6VTquza6cmUA\n",
    ") that we follow.\n",
    "\n",
    "- And here is the [Captain Lugaru's Assignment Miro Board](https://miro.com/app/board/uXjVL-vk0o4=/ \"Episodes Explained\")"
   ],
   "id": "4c4566e2d30852ab"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    " Episode 1: Basics of ML.\n",
    " Ok, so what is ML?:\n",
    " Machine learning is a branch of Ai that enables computer systems to learn and improve from experience without being explicitly programmed. It focuses on creating algorithms and models that can analyze data, identify patterns, and make decisions or predictions based on that data. Ml is not Like traditional programming:\n",
    " ![](./rules-data-logic-answers.png)"
   ],
   "id": "fbbd25d0674e0a74"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Ok, so rules + data goes into traditional programming give you answers, but with Machine learning you put in data and answers to get out perfect rules, so that later you can have the model predict the other answers much better and faster than traditional programming using these new rules, ok? well now we are going to look at how a neural network works down below:",
   "id": "63b7289987754295"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "![](layers.png)\n",
   "id": "3a2ad8b528b6de0"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "A group of Neurons that are side by side is called a layer, and you can have multiple layers that all communicate with each other and eventually coming up with a prediction or solution. but now that you understand the very basics of ML we will start Class 1 Coding aka the \"hello world\" of ML!:\n",
   "id": "53ec3d8ae9d9d7a3"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-07T15:28:33.305636Z",
     "start_time": "2025-01-07T15:28:32.073540Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import keras # imports\n",
    "import numpy as np\n",
    "model = keras.Sequential([keras.layers.Dense(units=1, input_shape=[1])]) # This line creates a machine learning model using Keras, structured as a sequence of layers. It has a single dense (fully connected) layer with 1 unit (neuron) and expects input data with one feature (dimension).\n",
    "\n",
    "model.compile(optimizer='sgd', loss='mean_squared_error') # This line sets up the model to learn by using the Stochastic Gradient Descent (SGD) optimizer to update its weights. It uses mean squared error to measure how far predictions are from the actual values during training.\n",
    "\n",
    "xs = np.array([-1.0, 0.0, 1.0, 2.0, 3.0, 4.0], dtype=float) # data used for x and y arrays\n",
    "ys = np.array([-3.0, -1.0, 1.0, 3.0, 5.0, 7.0], dtype=float)\n",
    "\n",
    "model.fit(xs, ys, epochs=200)#model is fitted and trained on the x and y and is given a number of epochs\n",
    "\n",
    "outcome = model.predict(np.array([4.0]))# model predicts what an x of 4 will mean for y\n",
    "print(outcome.round()) # should predict the right answer: 7.\n"
   ],
   "id": "bdb34a8ad01b63ac",
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "dlopen(/Users/anton/miniforge3/envs/ml/lib/python3.12/site-packages/tensorflow/python/platform/_pywrap_cpu_feature_guard.so, 0x0002): Symbol not found: __ZN4absl12lts_2024072212log_internal10LogMessagelsIbLi0EEERS2_RKT_\n  Referenced from: <0334E7A4-ECCB-3FBA-BC41-C55ED08D7613> /Users/anton/miniforge3/envs/ml/lib/python3.12/site-packages/tensorflow/libtensorflow_framework.2.dylib\n  Expected in:     <E99B267F-7144-31DD-A5D4-F5B0B82894DA> /Users/anton/miniforge3/envs/ml/lib/libabsl_log_internal_message.2407.0.0.dylib",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mImportError\u001B[0m                               Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[1], line 1\u001B[0m\n\u001B[0;32m----> 1\u001B[0m \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;21;01mkeras\u001B[39;00m \u001B[38;5;66;03m# imports\u001B[39;00m\n\u001B[1;32m      2\u001B[0m \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;21;01mnumpy\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m \u001B[38;5;21;01mnp\u001B[39;00m\n\u001B[1;32m      3\u001B[0m model \u001B[38;5;241m=\u001B[39m keras\u001B[38;5;241m.\u001B[39mSequential([keras\u001B[38;5;241m.\u001B[39mlayers\u001B[38;5;241m.\u001B[39mDense(units\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m1\u001B[39m, input_shape\u001B[38;5;241m=\u001B[39m[\u001B[38;5;241m1\u001B[39m])]) \u001B[38;5;66;03m# This line creates a machine learning model using Keras, structured as a sequence of layers. It has a single dense (fully connected) layer with 1 unit (neuron) and expects input data with one feature (dimension).\u001B[39;00m\n",
      "File \u001B[0;32m~/miniforge3/envs/ml/lib/python3.12/site-packages/keras/__init__.py:2\u001B[0m\n\u001B[1;32m      1\u001B[0m \u001B[38;5;66;03m# DO NOT EDIT. Generated by api_gen.sh\u001B[39;00m\n\u001B[0;32m----> 2\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mkeras\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mapi\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m DTypePolicy\n\u001B[1;32m      3\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mkeras\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mapi\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m FloatDTypePolicy\n\u001B[1;32m      4\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mkeras\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mapi\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m Function\n",
      "File \u001B[0;32m~/miniforge3/envs/ml/lib/python3.12/site-packages/keras/api/__init__.py:8\u001B[0m\n\u001B[1;32m      1\u001B[0m \u001B[38;5;124;03m\"\"\"DO NOT EDIT.\u001B[39;00m\n\u001B[1;32m      2\u001B[0m \n\u001B[1;32m      3\u001B[0m \u001B[38;5;124;03mThis file was autogenerated. Do not edit it by hand,\u001B[39;00m\n\u001B[1;32m      4\u001B[0m \u001B[38;5;124;03msince your modifications would be overwritten.\u001B[39;00m\n\u001B[1;32m      5\u001B[0m \u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[0;32m----> 8\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mkeras\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mapi\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m activations\n\u001B[1;32m      9\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mkeras\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mapi\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m applications\n\u001B[1;32m     10\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mkeras\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mapi\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m backend\n",
      "File \u001B[0;32m~/miniforge3/envs/ml/lib/python3.12/site-packages/keras/api/activations/__init__.py:7\u001B[0m\n\u001B[1;32m      1\u001B[0m \u001B[38;5;124;03m\"\"\"DO NOT EDIT.\u001B[39;00m\n\u001B[1;32m      2\u001B[0m \n\u001B[1;32m      3\u001B[0m \u001B[38;5;124;03mThis file was autogenerated. Do not edit it by hand,\u001B[39;00m\n\u001B[1;32m      4\u001B[0m \u001B[38;5;124;03msince your modifications would be overwritten.\u001B[39;00m\n\u001B[1;32m      5\u001B[0m \u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[0;32m----> 7\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mkeras\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01msrc\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mactivations\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m deserialize\n\u001B[1;32m      8\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mkeras\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01msrc\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mactivations\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m get\n\u001B[1;32m      9\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mkeras\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01msrc\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mactivations\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m serialize\n",
      "File \u001B[0;32m~/miniforge3/envs/ml/lib/python3.12/site-packages/keras/src/__init__.py:1\u001B[0m\n\u001B[0;32m----> 1\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mkeras\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01msrc\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m activations\n\u001B[1;32m      2\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mkeras\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01msrc\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m applications\n\u001B[1;32m      3\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mkeras\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01msrc\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m backend\n",
      "File \u001B[0;32m~/miniforge3/envs/ml/lib/python3.12/site-packages/keras/src/activations/__init__.py:3\u001B[0m\n\u001B[1;32m      1\u001B[0m \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;21;01mtypes\u001B[39;00m\n\u001B[0;32m----> 3\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mkeras\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01msrc\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mactivations\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mactivations\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m celu\n\u001B[1;32m      4\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mkeras\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01msrc\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mactivations\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mactivations\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m elu\n\u001B[1;32m      5\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mkeras\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01msrc\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mactivations\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mactivations\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m exponential\n",
      "File \u001B[0;32m~/miniforge3/envs/ml/lib/python3.12/site-packages/keras/src/activations/activations.py:1\u001B[0m\n\u001B[0;32m----> 1\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mkeras\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01msrc\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m backend\n\u001B[1;32m      2\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mkeras\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01msrc\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m ops\n\u001B[1;32m      3\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mkeras\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01msrc\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mapi_export\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m keras_export\n",
      "File \u001B[0;32m~/miniforge3/envs/ml/lib/python3.12/site-packages/keras/src/backend/__init__.py:10\u001B[0m\n\u001B[1;32m      7\u001B[0m     \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;21;01mtorch\u001B[39;00m\n\u001B[1;32m      9\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mkeras\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01msrc\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mapi_export\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m keras_export\n\u001B[0;32m---> 10\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mkeras\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01msrc\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mbackend\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mcommon\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mdtypes\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m result_type\n\u001B[1;32m     11\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mkeras\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01msrc\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mbackend\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mcommon\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mkeras_tensor\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m KerasTensor\n\u001B[1;32m     12\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mkeras\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01msrc\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mbackend\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mcommon\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mkeras_tensor\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m any_symbolic_tensors\n",
      "File \u001B[0;32m~/miniforge3/envs/ml/lib/python3.12/site-packages/keras/src/backend/common/__init__.py:2\u001B[0m\n\u001B[1;32m      1\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mkeras\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01msrc\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mbackend\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mcommon\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m backend_utils\n\u001B[0;32m----> 2\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mkeras\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01msrc\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mbackend\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mcommon\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mdtypes\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m result_type\n\u001B[1;32m      3\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mkeras\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01msrc\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mbackend\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mcommon\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mvariables\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m AutocastScope\n\u001B[1;32m      4\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mkeras\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01msrc\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mbackend\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mcommon\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mvariables\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m Variable \u001B[38;5;28;01mas\u001B[39;00m KerasVariable\n",
      "File \u001B[0;32m~/miniforge3/envs/ml/lib/python3.12/site-packages/keras/src/backend/common/dtypes.py:5\u001B[0m\n\u001B[1;32m      3\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mkeras\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01msrc\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mapi_export\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m keras_export\n\u001B[1;32m      4\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mkeras\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01msrc\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mbackend\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m config\n\u001B[0;32m----> 5\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mkeras\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01msrc\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mbackend\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mcommon\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mvariables\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m standardize_dtype\n\u001B[1;32m      7\u001B[0m BOOL_TYPES \u001B[38;5;241m=\u001B[39m (\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mbool\u001B[39m\u001B[38;5;124m\"\u001B[39m,)\n\u001B[1;32m      8\u001B[0m INT_TYPES \u001B[38;5;241m=\u001B[39m (\n\u001B[1;32m      9\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124muint8\u001B[39m\u001B[38;5;124m\"\u001B[39m,\n\u001B[1;32m     10\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124muint16\u001B[39m\u001B[38;5;124m\"\u001B[39m,\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m     16\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mint64\u001B[39m\u001B[38;5;124m\"\u001B[39m,\n\u001B[1;32m     17\u001B[0m )\n",
      "File \u001B[0;32m~/miniforge3/envs/ml/lib/python3.12/site-packages/keras/src/backend/common/variables.py:11\u001B[0m\n\u001B[1;32m      9\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mkeras\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01msrc\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mbackend\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mcommon\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mstateless_scope\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m get_stateless_scope\n\u001B[1;32m     10\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mkeras\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01msrc\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mbackend\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mcommon\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mstateless_scope\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m in_stateless_scope\n\u001B[0;32m---> 11\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mkeras\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01msrc\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mutils\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mmodule_utils\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m tensorflow \u001B[38;5;28;01mas\u001B[39;00m tf\n\u001B[1;32m     12\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mkeras\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01msrc\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mutils\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mnaming\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m auto_name\n\u001B[1;32m     15\u001B[0m \u001B[38;5;28;01mclass\u001B[39;00m \u001B[38;5;21;01mVariable\u001B[39;00m:\n",
      "File \u001B[0;32m~/miniforge3/envs/ml/lib/python3.12/site-packages/keras/src/utils/__init__.py:1\u001B[0m\n\u001B[0;32m----> 1\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mkeras\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01msrc\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mutils\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01maudio_dataset_utils\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m audio_dataset_from_directory\n\u001B[1;32m      2\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mkeras\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01msrc\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mutils\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mdataset_utils\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m split_dataset\n\u001B[1;32m      3\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mkeras\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01msrc\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mutils\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mfile_utils\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m get_file\n",
      "File \u001B[0;32m~/miniforge3/envs/ml/lib/python3.12/site-packages/keras/src/utils/audio_dataset_utils.py:4\u001B[0m\n\u001B[1;32m      1\u001B[0m \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;21;01mnumpy\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m \u001B[38;5;21;01mnp\u001B[39;00m\n\u001B[1;32m      3\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mkeras\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01msrc\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mapi_export\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m keras_export\n\u001B[0;32m----> 4\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mkeras\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01msrc\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mutils\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m dataset_utils\n\u001B[1;32m      5\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mkeras\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01msrc\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mutils\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mmodule_utils\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m tensorflow \u001B[38;5;28;01mas\u001B[39;00m tf\n\u001B[1;32m      6\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mkeras\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01msrc\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mutils\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mmodule_utils\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m tensorflow_io \u001B[38;5;28;01mas\u001B[39;00m tfio\n",
      "File \u001B[0;32m~/miniforge3/envs/ml/lib/python3.12/site-packages/keras/src/utils/dataset_utils.py:9\u001B[0m\n\u001B[1;32m      5\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mmultiprocessing\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mpool\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m ThreadPool\n\u001B[1;32m      7\u001B[0m \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;21;01mnumpy\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m \u001B[38;5;21;01mnp\u001B[39;00m\n\u001B[0;32m----> 9\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mkeras\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01msrc\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m tree\n\u001B[1;32m     10\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mkeras\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01msrc\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mapi_export\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m keras_export\n\u001B[1;32m     11\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mkeras\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01msrc\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mutils\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m io_utils\n",
      "File \u001B[0;32m~/miniforge3/envs/ml/lib/python3.12/site-packages/keras/src/tree/__init__.py:1\u001B[0m\n\u001B[0;32m----> 1\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mkeras\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01msrc\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mtree\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mtree_api\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m assert_same_paths\n\u001B[1;32m      2\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mkeras\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01msrc\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mtree\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mtree_api\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m assert_same_structure\n\u001B[1;32m      3\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mkeras\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01msrc\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mtree\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mtree_api\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m flatten\n",
      "File \u001B[0;32m~/miniforge3/envs/ml/lib/python3.12/site-packages/keras/src/tree/tree_api.py:6\u001B[0m\n\u001B[1;32m      3\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mkeras\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01msrc\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mutils\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mmodule_utils\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m optree\n\u001B[1;32m      5\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m optree\u001B[38;5;241m.\u001B[39mavailable:\n\u001B[0;32m----> 6\u001B[0m     \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mkeras\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01msrc\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mtree\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m optree_impl \u001B[38;5;28;01mas\u001B[39;00m tree_impl\n\u001B[1;32m      7\u001B[0m \u001B[38;5;28;01melif\u001B[39;00m dmtree\u001B[38;5;241m.\u001B[39mavailable:\n\u001B[1;32m      8\u001B[0m     \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mkeras\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01msrc\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mtree\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m dmtree_impl \u001B[38;5;28;01mas\u001B[39;00m tree_impl\n",
      "File \u001B[0;32m~/miniforge3/envs/ml/lib/python3.12/site-packages/keras/src/tree/optree_impl.py:17\u001B[0m\n\u001B[1;32m     15\u001B[0m \u001B[38;5;66;03m# Register backend-specific node classes\u001B[39;00m\n\u001B[1;32m     16\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m backend() \u001B[38;5;241m==\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mtensorflow\u001B[39m\u001B[38;5;124m\"\u001B[39m:\n\u001B[0;32m---> 17\u001B[0m     \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mtensorflow\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mpython\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mtrackable\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mdata_structures\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m ListWrapper\n\u001B[1;32m     19\u001B[0m     optree\u001B[38;5;241m.\u001B[39mregister_pytree_node(\n\u001B[1;32m     20\u001B[0m         ListWrapper,\n\u001B[1;32m     21\u001B[0m         \u001B[38;5;28;01mlambda\u001B[39;00m x: (x, \u001B[38;5;28;01mNone\u001B[39;00m),\n\u001B[1;32m     22\u001B[0m         \u001B[38;5;28;01mlambda\u001B[39;00m metadata, children: ListWrapper(\u001B[38;5;28mlist\u001B[39m(children)),\n\u001B[1;32m     23\u001B[0m         namespace\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mkeras\u001B[39m\u001B[38;5;124m\"\u001B[39m,\n\u001B[1;32m     24\u001B[0m     )\n\u001B[1;32m     26\u001B[0m     \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mtensorflow\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mpython\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mtrackable\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mdata_structures\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m _DictWrapper\n",
      "File \u001B[0;32m~/miniforge3/envs/ml/lib/python3.12/site-packages/tensorflow/__init__.py:38\u001B[0m\n\u001B[1;32m     35\u001B[0m \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;21;01msys\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m \u001B[38;5;21;01m_sys\u001B[39;00m\n\u001B[1;32m     37\u001B[0m \u001B[38;5;66;03m# Do not remove this line; See https://github.com/tensorflow/tensorflow/issues/42596\u001B[39;00m\n\u001B[0;32m---> 38\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mtensorflow\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mpython\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m pywrap_tensorflow \u001B[38;5;28;01mas\u001B[39;00m _pywrap_tensorflow  \u001B[38;5;66;03m# pylint: disable=unused-import\u001B[39;00m\n\u001B[1;32m     39\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mtensorflow\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mpython\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mtools\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m module_util \u001B[38;5;28;01mas\u001B[39;00m _module_util\n\u001B[1;32m     40\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mtensorflow\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mpython\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mutil\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mlazy_loader\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m KerasLazyLoader \u001B[38;5;28;01mas\u001B[39;00m _KerasLazyLoader\n",
      "File \u001B[0;32m~/miniforge3/envs/ml/lib/python3.12/site-packages/tensorflow/python/pywrap_tensorflow.py:34\u001B[0m\n\u001B[1;32m     29\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mtensorflow\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mpython\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mplatform\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m self_check\n\u001B[1;32m     31\u001B[0m \u001B[38;5;66;03m# TODO(mdan): Cleanup antipattern: import for side effects.\u001B[39;00m\n\u001B[1;32m     32\u001B[0m \n\u001B[1;32m     33\u001B[0m \u001B[38;5;66;03m# Perform pre-load sanity checks in order to produce a more actionable error.\u001B[39;00m\n\u001B[0;32m---> 34\u001B[0m \u001B[43mself_check\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mpreload_check\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     36\u001B[0m \u001B[38;5;66;03m# pylint: disable=wildcard-import,g-import-not-at-top,unused-import,line-too-long\u001B[39;00m\n\u001B[1;32m     38\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m     39\u001B[0m   \u001B[38;5;66;03m# This import is expected to fail if there is an explicit shared object\u001B[39;00m\n\u001B[1;32m     40\u001B[0m   \u001B[38;5;66;03m# dependency (with_framework_lib=true), since we do not need RTLD_GLOBAL.\u001B[39;00m\n",
      "File \u001B[0;32m~/miniforge3/envs/ml/lib/python3.12/site-packages/tensorflow/python/platform/self_check.py:63\u001B[0m, in \u001B[0;36mpreload_check\u001B[0;34m()\u001B[0m\n\u001B[1;32m     50\u001B[0m       \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mImportError\u001B[39;00m(\n\u001B[1;32m     51\u001B[0m           \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mCould not find the DLL(s) \u001B[39m\u001B[38;5;132;01m%r\u001B[39;00m\u001B[38;5;124m. TensorFlow requires that these DLLs \u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m     52\u001B[0m           \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mbe installed in a directory that is named in your \u001B[39m\u001B[38;5;132;01m%%\u001B[39;00m\u001B[38;5;124mPATH\u001B[39m\u001B[38;5;132;01m%%\u001B[39;00m\u001B[38;5;124m \u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m     56\u001B[0m           \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mhttps://support.microsoft.com/help/2977003/the-latest-supported-visual-c-downloads\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m     57\u001B[0m           \u001B[38;5;241m%\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m or \u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;241m.\u001B[39mjoin(missing))\n\u001B[1;32m     58\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m     59\u001B[0m   \u001B[38;5;66;03m# Load a library that performs CPU feature guard checking.  Doing this here\u001B[39;00m\n\u001B[1;32m     60\u001B[0m   \u001B[38;5;66;03m# as a preload check makes it more likely that we detect any CPU feature\u001B[39;00m\n\u001B[1;32m     61\u001B[0m   \u001B[38;5;66;03m# incompatibilities before we trigger them (which would typically result in\u001B[39;00m\n\u001B[1;32m     62\u001B[0m   \u001B[38;5;66;03m# SIGILL).\u001B[39;00m\n\u001B[0;32m---> 63\u001B[0m   \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mtensorflow\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mpython\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mplatform\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m _pywrap_cpu_feature_guard\n\u001B[1;32m     64\u001B[0m   _pywrap_cpu_feature_guard\u001B[38;5;241m.\u001B[39mInfoAboutUnusedCPUFeatures()\n",
      "\u001B[0;31mImportError\u001B[0m: dlopen(/Users/anton/miniforge3/envs/ml/lib/python3.12/site-packages/tensorflow/python/platform/_pywrap_cpu_feature_guard.so, 0x0002): Symbol not found: __ZN4absl12lts_2024072212log_internal10LogMessagelsIbLi0EEERS2_RKT_\n  Referenced from: <0334E7A4-ECCB-3FBA-BC41-C55ED08D7613> /Users/anton/miniforge3/envs/ml/lib/python3.12/site-packages/tensorflow/libtensorflow_framework.2.dylib\n  Expected in:     <E99B267F-7144-31DD-A5D4-F5B0B82894DA> /Users/anton/miniforge3/envs/ml/lib/libabsl_log_internal_message.2407.0.0.dylib"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "Now,Here is the Exercise for the episode and if you are stuck with it the answer is down below:\n",
    "https://colab.research.google.com/github/lmoroney/dlaicourse/blob/master/Exercises/Exercise%201%20-%20House%20Prices/Exercise_1_House_Prices_Question.ipynb\n"
   ],
   "id": "a08a9aaf661e7f36"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-10T16:43:31.594074Z",
     "start_time": "2024-12-10T16:43:12.046253Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import keras\n",
    "\n",
    "# Define the model: a simple Sequential model with one dense layer\n",
    "model = keras.Sequential([\n",
    "    keras.layers.Dense(units=1, input_shape=[1])  # One neuron, one input feature\n",
    "])\n",
    "\n",
    "# Compile the model: specify optimizer, loss function, and metrics\n",
    "model.compile(optimizer='sgd',  # Stochastic Gradient Descent optimizer\n",
    "              loss='mean_squared_error')  # Use mean squared error for regression tasks\n",
    "\n",
    "# Input data (xs) and output data (ys) representing a simple linear relationship\n",
    "xs = np.array([-1.0, 0.0, 1.0, 2.0, 3.0, 4.0], dtype=float)  # Example inputs\n",
    "ys = np.array([-3.0, -1.0, 1.0, 3.0, 5.0, 7.0], dtype=float)  # Corresponding outputs\n",
    "\n",
    "# Train the model\n",
    "model.fit(xs, ys, epochs=500)  # Train for 500 epochs to minimize loss\n",
    "\n",
    "# Use the model to predict a value\n",
    "print(model.predict(np.array([7.0])))\n",
    "  # Predict the output for input 7.0\n"
   ],
   "id": "f54451ee831fbfd1",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/500\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 204ms/step - loss: 26.4432\n",
      "Epoch 2/500\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 44ms/step - loss: 21.1012\n",
      "Epoch 3/500\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 37ms/step - loss: 16.8923\n",
      "Epoch 4/500\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 38ms/step - loss: 13.5749\n",
      "Epoch 5/500\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 36ms/step - loss: 10.9591\n",
      "Epoch 6/500\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 36ms/step - loss: 8.8954\n",
      "Epoch 7/500\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 37ms/step - loss: 7.2662\n",
      "Epoch 8/500\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 39ms/step - loss: 5.9789\n",
      "Epoch 9/500\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 37ms/step - loss: 4.9607\n",
      "Epoch 10/500\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 36ms/step - loss: 4.1544\n",
      "Epoch 11/500\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 37ms/step - loss: 3.5149\n",
      "Epoch 12/500\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 36ms/step - loss: 3.0066\n",
      "Epoch 13/500\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 36ms/step - loss: 2.6018\n",
      "Epoch 14/500\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 37ms/step - loss: 2.2785\n",
      "Epoch 15/500\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 49ms/step - loss: 2.0194\n",
      "Epoch 16/500\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 47ms/step - loss: 1.8108\n",
      "Epoch 17/500\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 46ms/step - loss: 1.6422\n",
      "Epoch 18/500\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 42ms/step - loss: 1.5051\n",
      "Epoch 19/500\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 43ms/step - loss: 1.3928\n",
      "Epoch 20/500\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 47ms/step - loss: 1.3002\n",
      "Epoch 21/500\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 45ms/step - loss: 1.2231\n",
      "Epoch 22/500\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 44ms/step - loss: 1.1584\n",
      "Epoch 23/500\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 45ms/step - loss: 1.1034\n",
      "Epoch 24/500\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 42ms/step - loss: 1.0562\n",
      "Epoch 25/500\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 43ms/step - loss: 1.0152\n",
      "Epoch 26/500\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 44ms/step - loss: 0.9792\n",
      "Epoch 27/500\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 45ms/step - loss: 0.9471\n",
      "Epoch 28/500\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 46ms/step - loss: 0.9183\n",
      "Epoch 29/500\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 42ms/step - loss: 0.8920\n",
      "Epoch 30/500\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 45ms/step - loss: 0.8679\n",
      "Epoch 31/500\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 44ms/step - loss: 0.8455\n",
      "Epoch 32/500\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 42ms/step - loss: 0.8245\n",
      "Epoch 33/500\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 46ms/step - loss: 0.8048\n",
      "Epoch 34/500\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 41ms/step - loss: 0.7860\n",
      "Epoch 35/500\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 44ms/step - loss: 0.7681\n",
      "Epoch 36/500\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 43ms/step - loss: 0.7509\n",
      "Epoch 37/500\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 43ms/step - loss: 0.7344\n",
      "Epoch 38/500\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 43ms/step - loss: 0.7185\n",
      "Epoch 39/500\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 39ms/step - loss: 0.7031\n",
      "Epoch 40/500\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 40ms/step - loss: 0.6881\n",
      "Epoch 41/500\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 40ms/step - loss: 0.6735\n",
      "Epoch 42/500\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 41ms/step - loss: 0.6594\n",
      "Epoch 43/500\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 45ms/step - loss: 0.6456\n",
      "Epoch 44/500\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 43ms/step - loss: 0.6321\n",
      "Epoch 45/500\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 48ms/step - loss: 0.6190\n",
      "Epoch 46/500\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 42ms/step - loss: 0.6061\n",
      "Epoch 47/500\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 40ms/step - loss: 0.5936\n",
      "Epoch 48/500\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 50ms/step - loss: 0.5813\n",
      "Epoch 49/500\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 45ms/step - loss: 0.5693\n",
      "Epoch 50/500\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 47ms/step - loss: 0.5576\n",
      "Epoch 51/500\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 50ms/step - loss: 0.5461\n",
      "Epoch 52/500\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 43ms/step - loss: 0.5348\n",
      "Epoch 53/500\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 43ms/step - loss: 0.5238\n",
      "Epoch 54/500\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 41ms/step - loss: 0.5131\n",
      "Epoch 55/500\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 42ms/step - loss: 0.5025\n",
      "Epoch 56/500\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 49ms/step - loss: 0.4922\n",
      "Epoch 57/500\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 44ms/step - loss: 0.4820\n",
      "Epoch 58/500\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 45ms/step - loss: 0.4721\n",
      "Epoch 59/500\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 43ms/step - loss: 0.4624\n",
      "Epoch 60/500\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 42ms/step - loss: 0.4529\n",
      "Epoch 61/500\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 40ms/step - loss: 0.4436\n",
      "Epoch 62/500\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 41ms/step - loss: 0.4345\n",
      "Epoch 63/500\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 41ms/step - loss: 0.4256\n",
      "Epoch 64/500\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 42ms/step - loss: 0.4168\n",
      "Epoch 65/500\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 41ms/step - loss: 0.4083\n",
      "Epoch 66/500\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 40ms/step - loss: 0.3999\n",
      "Epoch 67/500\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 40ms/step - loss: 0.3917\n",
      "Epoch 68/500\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 42ms/step - loss: 0.3836\n",
      "Epoch 69/500\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 44ms/step - loss: 0.3757\n",
      "Epoch 70/500\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 49ms/step - loss: 0.3680\n",
      "Epoch 71/500\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 52ms/step - loss: 0.3605\n",
      "Epoch 72/500\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 44ms/step - loss: 0.3531\n",
      "Epoch 73/500\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 49ms/step - loss: 0.3458\n",
      "Epoch 74/500\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 55ms/step - loss: 0.3387\n",
      "Epoch 75/500\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 61ms/step - loss: 0.3318\n",
      "Epoch 76/500\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 49ms/step - loss: 0.3249\n",
      "Epoch 77/500\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 48ms/step - loss: 0.3183\n",
      "Epoch 78/500\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 44ms/step - loss: 0.3117\n",
      "Epoch 79/500\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 43ms/step - loss: 0.3053\n",
      "Epoch 80/500\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 46ms/step - loss: 0.2991\n",
      "Epoch 81/500\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 41ms/step - loss: 0.2929\n",
      "Epoch 82/500\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 41ms/step - loss: 0.2869\n",
      "Epoch 83/500\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 45ms/step - loss: 0.2810\n",
      "Epoch 84/500\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 42ms/step - loss: 0.2752\n",
      "Epoch 85/500\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 43ms/step - loss: 0.2696\n",
      "Epoch 86/500\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 46ms/step - loss: 0.2640\n",
      "Epoch 87/500\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 43ms/step - loss: 0.2586\n",
      "Epoch 88/500\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 61ms/step - loss: 0.2533\n",
      "Epoch 89/500\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 40ms/step - loss: 0.2481\n",
      "Epoch 90/500\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 39ms/step - loss: 0.2430\n",
      "Epoch 91/500\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 44ms/step - loss: 0.2380\n",
      "Epoch 92/500\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 42ms/step - loss: 0.2331\n",
      "Epoch 93/500\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 41ms/step - loss: 0.2283\n",
      "Epoch 94/500\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 44ms/step - loss: 0.2236\n",
      "Epoch 95/500\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 42ms/step - loss: 0.2190\n",
      "Epoch 96/500\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 41ms/step - loss: 0.2145\n",
      "Epoch 97/500\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 53ms/step - loss: 0.2101\n",
      "Epoch 98/500\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 42ms/step - loss: 0.2058\n",
      "Epoch 99/500\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 46ms/step - loss: 0.2016\n",
      "Epoch 100/500\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 58ms/step - loss: 0.1975\n",
      "Epoch 101/500\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 50ms/step - loss: 0.1934\n",
      "Epoch 102/500\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 45ms/step - loss: 0.1894\n",
      "Epoch 103/500\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 48ms/step - loss: 0.1855\n",
      "Epoch 104/500\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 48ms/step - loss: 0.1817\n",
      "Epoch 105/500\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 46ms/step - loss: 0.1780\n",
      "Epoch 106/500\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 45ms/step - loss: 0.1743\n",
      "Epoch 107/500\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 43ms/step - loss: 0.1708\n",
      "Epoch 108/500\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 48ms/step - loss: 0.1672\n",
      "Epoch 109/500\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 42ms/step - loss: 0.1638\n",
      "Epoch 110/500\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 53ms/step - loss: 0.1604\n",
      "Epoch 111/500\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 45ms/step - loss: 0.1572\n",
      "Epoch 112/500\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 55ms/step - loss: 0.1539\n",
      "Epoch 113/500\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 60ms/step - loss: 0.1508\n",
      "Epoch 114/500\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 60ms/step - loss: 0.1477\n",
      "Epoch 115/500\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 61ms/step - loss: 0.1446\n",
      "Epoch 116/500\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 54ms/step - loss: 0.1417\n",
      "Epoch 117/500\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 56ms/step - loss: 0.1388\n",
      "Epoch 118/500\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 55ms/step - loss: 0.1359\n",
      "Epoch 119/500\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 54ms/step - loss: 0.1331\n",
      "Epoch 120/500\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 57ms/step - loss: 0.1304\n",
      "Epoch 121/500\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 44ms/step - loss: 0.1277\n",
      "Epoch 122/500\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 40ms/step - loss: 0.1251\n",
      "Epoch 123/500\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 43ms/step - loss: 0.1225\n",
      "Epoch 124/500\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 47ms/step - loss: 0.1200\n",
      "Epoch 125/500\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 40ms/step - loss: 0.1175\n",
      "Epoch 126/500\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 42ms/step - loss: 0.1151\n",
      "Epoch 127/500\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 42ms/step - loss: 0.1127\n",
      "Epoch 128/500\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 45ms/step - loss: 0.1104\n",
      "Epoch 129/500\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 46ms/step - loss: 0.1082\n",
      "Epoch 130/500\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 46ms/step - loss: 0.1059\n",
      "Epoch 131/500\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 49ms/step - loss: 0.1038\n",
      "Epoch 132/500\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 47ms/step - loss: 0.1016\n",
      "Epoch 133/500\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 49ms/step - loss: 0.0995\n",
      "Epoch 134/500\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 44ms/step - loss: 0.0975\n",
      "Epoch 135/500\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 43ms/step - loss: 0.0955\n",
      "Epoch 136/500\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 43ms/step - loss: 0.0935\n",
      "Epoch 137/500\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 44ms/step - loss: 0.0916\n",
      "Epoch 138/500\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 45ms/step - loss: 0.0897\n",
      "Epoch 139/500\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 46ms/step - loss: 0.0879\n",
      "Epoch 140/500\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 42ms/step - loss: 0.0861\n",
      "Epoch 141/500\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 45ms/step - loss: 0.0843\n",
      "Epoch 142/500\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 44ms/step - loss: 0.0826\n",
      "Epoch 143/500\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 43ms/step - loss: 0.0809\n",
      "Epoch 144/500\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 44ms/step - loss: 0.0792\n",
      "Epoch 145/500\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 44ms/step - loss: 0.0776\n",
      "Epoch 146/500\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 47ms/step - loss: 0.0760\n",
      "Epoch 147/500\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 49ms/step - loss: 0.0744\n",
      "Epoch 148/500\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 43ms/step - loss: 0.0729\n",
      "Epoch 149/500\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 42ms/step - loss: 0.0714\n",
      "Epoch 150/500\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 45ms/step - loss: 0.0700\n",
      "Epoch 151/500\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 42ms/step - loss: 0.0685\n",
      "Epoch 152/500\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 41ms/step - loss: 0.0671\n",
      "Epoch 153/500\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 41ms/step - loss: 0.0657\n",
      "Epoch 154/500\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 41ms/step - loss: 0.0644\n",
      "Epoch 155/500\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 41ms/step - loss: 0.0631\n",
      "Epoch 156/500\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 40ms/step - loss: 0.0618\n",
      "Epoch 157/500\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 39ms/step - loss: 0.0605\n",
      "Epoch 158/500\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 44ms/step - loss: 0.0592\n",
      "Epoch 159/500\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 41ms/step - loss: 0.0580\n",
      "Epoch 160/500\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 39ms/step - loss: 0.0568\n",
      "Epoch 161/500\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 39ms/step - loss: 0.0557\n",
      "Epoch 162/500\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 41ms/step - loss: 0.0545\n",
      "Epoch 163/500\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 41ms/step - loss: 0.0534\n",
      "Epoch 164/500\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 41ms/step - loss: 0.0523\n",
      "Epoch 165/500\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 40ms/step - loss: 0.0512\n",
      "Epoch 166/500\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 40ms/step - loss: 0.0502\n",
      "Epoch 167/500\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 42ms/step - loss: 0.0492\n",
      "Epoch 168/500\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 40ms/step - loss: 0.0481\n",
      "Epoch 169/500\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 38ms/step - loss: 0.0472\n",
      "Epoch 170/500\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 40ms/step - loss: 0.0462\n",
      "Epoch 171/500\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 39ms/step - loss: 0.0452\n",
      "Epoch 172/500\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 39ms/step - loss: 0.0443\n",
      "Epoch 173/500\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 37ms/step - loss: 0.0434\n",
      "Epoch 174/500\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 38ms/step - loss: 0.0425\n",
      "Epoch 175/500\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 39ms/step - loss: 0.0416\n",
      "Epoch 176/500\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 39ms/step - loss: 0.0408\n",
      "Epoch 177/500\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 42ms/step - loss: 0.0399\n",
      "Epoch 178/500\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 40ms/step - loss: 0.0391\n",
      "Epoch 179/500\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 39ms/step - loss: 0.0383\n",
      "Epoch 180/500\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 38ms/step - loss: 0.0375\n",
      "Epoch 181/500\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 38ms/step - loss: 0.0368\n",
      "Epoch 182/500\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 37ms/step - loss: 0.0360\n",
      "Epoch 183/500\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 37ms/step - loss: 0.0353\n",
      "Epoch 184/500\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 38ms/step - loss: 0.0345\n",
      "Epoch 185/500\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 39ms/step - loss: 0.0338\n",
      "Epoch 186/500\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 37ms/step - loss: 0.0331\n",
      "Epoch 187/500\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 37ms/step - loss: 0.0325\n",
      "Epoch 188/500\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 39ms/step - loss: 0.0318\n",
      "Epoch 189/500\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 38ms/step - loss: 0.0311\n",
      "Epoch 190/500\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 39ms/step - loss: 0.0305\n",
      "Epoch 191/500\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 40ms/step - loss: 0.0299\n",
      "Epoch 192/500\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 39ms/step - loss: 0.0293\n",
      "Epoch 193/500\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 38ms/step - loss: 0.0287\n",
      "Epoch 194/500\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 38ms/step - loss: 0.0281\n",
      "Epoch 195/500\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 38ms/step - loss: 0.0275\n",
      "Epoch 196/500\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 42ms/step - loss: 0.0269\n",
      "Epoch 197/500\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 41ms/step - loss: 0.0264\n",
      "Epoch 198/500\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 41ms/step - loss: 0.0258\n",
      "Epoch 199/500\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 39ms/step - loss: 0.0253\n",
      "Epoch 200/500\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 40ms/step - loss: 0.0248\n",
      "Epoch 201/500\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 37ms/step - loss: 0.0243\n",
      "Epoch 202/500\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 41ms/step - loss: 0.0238\n",
      "Epoch 203/500\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 39ms/step - loss: 0.0233\n",
      "Epoch 204/500\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 52ms/step - loss: 0.0228\n",
      "Epoch 205/500\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 44ms/step - loss: 0.0223\n",
      "Epoch 206/500\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 42ms/step - loss: 0.0219\n",
      "Epoch 207/500\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 42ms/step - loss: 0.0214\n",
      "Epoch 208/500\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 42ms/step - loss: 0.0210\n",
      "Epoch 209/500\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 42ms/step - loss: 0.0206\n",
      "Epoch 210/500\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 43ms/step - loss: 0.0201\n",
      "Epoch 211/500\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 42ms/step - loss: 0.0197\n",
      "Epoch 212/500\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 41ms/step - loss: 0.0193\n",
      "Epoch 213/500\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 45ms/step - loss: 0.0189\n",
      "Epoch 214/500\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 44ms/step - loss: 0.0185\n",
      "Epoch 215/500\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 41ms/step - loss: 0.0182\n",
      "Epoch 216/500\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 41ms/step - loss: 0.0178\n",
      "Epoch 217/500\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 44ms/step - loss: 0.0174\n",
      "Epoch 218/500\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 42ms/step - loss: 0.0171\n",
      "Epoch 219/500\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 42ms/step - loss: 0.0167\n",
      "Epoch 220/500\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 43ms/step - loss: 0.0164\n",
      "Epoch 221/500\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 44ms/step - loss: 0.0160\n",
      "Epoch 222/500\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 44ms/step - loss: 0.0157\n",
      "Epoch 223/500\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 41ms/step - loss: 0.0154\n",
      "Epoch 224/500\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 41ms/step - loss: 0.0151\n",
      "Epoch 225/500\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 42ms/step - loss: 0.0147\n",
      "Epoch 226/500\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 42ms/step - loss: 0.0144\n",
      "Epoch 227/500\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 41ms/step - loss: 0.0141\n",
      "Epoch 228/500\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 41ms/step - loss: 0.0139\n",
      "Epoch 229/500\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 149ms/step - loss: 0.0136\n",
      "Epoch 230/500\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 43ms/step - loss: 0.0133\n",
      "Epoch 231/500\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 41ms/step - loss: 0.0130\n",
      "Epoch 232/500\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 39ms/step - loss: 0.0128\n",
      "Epoch 233/500\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 38ms/step - loss: 0.0125\n",
      "Epoch 234/500\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 38ms/step - loss: 0.0122\n",
      "Epoch 235/500\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 39ms/step - loss: 0.0120\n",
      "Epoch 236/500\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 38ms/step - loss: 0.0117\n",
      "Epoch 237/500\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 41ms/step - loss: 0.0115\n",
      "Epoch 238/500\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 37ms/step - loss: 0.0113\n",
      "Epoch 239/500\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 37ms/step - loss: 0.0110\n",
      "Epoch 240/500\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 38ms/step - loss: 0.0108\n",
      "Epoch 241/500\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 38ms/step - loss: 0.0106\n",
      "Epoch 242/500\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 39ms/step - loss: 0.0104\n",
      "Epoch 243/500\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 39ms/step - loss: 0.0102\n",
      "Epoch 244/500\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 40ms/step - loss: 0.0099\n",
      "Epoch 245/500\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 42ms/step - loss: 0.0097\n",
      "Epoch 246/500\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 42ms/step - loss: 0.0095\n",
      "Epoch 247/500\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 42ms/step - loss: 0.0093\n",
      "Epoch 248/500\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 41ms/step - loss: 0.0092\n",
      "Epoch 249/500\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 41ms/step - loss: 0.0090\n",
      "Epoch 250/500\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 40ms/step - loss: 0.0088\n",
      "Epoch 251/500\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 40ms/step - loss: 0.0086\n",
      "Epoch 252/500\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 41ms/step - loss: 0.0084\n",
      "Epoch 253/500\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 41ms/step - loss: 0.0082\n",
      "Epoch 254/500\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 40ms/step - loss: 0.0081\n",
      "Epoch 255/500\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 41ms/step - loss: 0.0079\n",
      "Epoch 256/500\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 40ms/step - loss: 0.0078\n",
      "Epoch 257/500\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 41ms/step - loss: 0.0076\n",
      "Epoch 258/500\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 41ms/step - loss: 0.0074\n",
      "Epoch 259/500\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 41ms/step - loss: 0.0073\n",
      "Epoch 260/500\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 42ms/step - loss: 0.0071\n",
      "Epoch 261/500\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 43ms/step - loss: 0.0070\n",
      "Epoch 262/500\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 43ms/step - loss: 0.0068\n",
      "Epoch 263/500\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 43ms/step - loss: 0.0067\n",
      "Epoch 264/500\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 43ms/step - loss: 0.0066\n",
      "Epoch 265/500\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 41ms/step - loss: 0.0064\n",
      "Epoch 266/500\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 42ms/step - loss: 0.0063\n",
      "Epoch 267/500\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 44ms/step - loss: 0.0062\n",
      "Epoch 268/500\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 43ms/step - loss: 0.0060\n",
      "Epoch 269/500\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 42ms/step - loss: 0.0059\n",
      "Epoch 270/500\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 42ms/step - loss: 0.0058\n",
      "Epoch 271/500\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 42ms/step - loss: 0.0057\n",
      "Epoch 272/500\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 43ms/step - loss: 0.0056\n",
      "Epoch 273/500\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 42ms/step - loss: 0.0054\n",
      "Epoch 274/500\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 40ms/step - loss: 0.0053\n",
      "Epoch 275/500\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 41ms/step - loss: 0.0052\n",
      "Epoch 276/500\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 41ms/step - loss: 0.0051\n",
      "Epoch 277/500\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 42ms/step - loss: 0.0050\n",
      "Epoch 278/500\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 40ms/step - loss: 0.0049\n",
      "Epoch 279/500\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 42ms/step - loss: 0.0048\n",
      "Epoch 280/500\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 39ms/step - loss: 0.0047\n",
      "Epoch 281/500\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 40ms/step - loss: 0.0046\n",
      "Epoch 282/500\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 41ms/step - loss: 0.0045\n",
      "Epoch 283/500\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 41ms/step - loss: 0.0044\n",
      "Epoch 284/500\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 40ms/step - loss: 0.0043\n",
      "Epoch 285/500\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 41ms/step - loss: 0.0042\n",
      "Epoch 286/500\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 44ms/step - loss: 0.0042\n",
      "Epoch 287/500\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 41ms/step - loss: 0.0041\n",
      "Epoch 288/500\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 45ms/step - loss: 0.0040\n",
      "Epoch 289/500\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 44ms/step - loss: 0.0039\n",
      "Epoch 290/500\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 43ms/step - loss: 0.0038\n",
      "Epoch 291/500\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 43ms/step - loss: 0.0037\n",
      "Epoch 292/500\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 39ms/step - loss: 0.0037\n",
      "Epoch 293/500\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 38ms/step - loss: 0.0036\n",
      "Epoch 294/500\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 39ms/step - loss: 0.0035\n",
      "Epoch 295/500\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 42ms/step - loss: 0.0035\n",
      "Epoch 296/500\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 38ms/step - loss: 0.0034\n",
      "Epoch 297/500\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 38ms/step - loss: 0.0033\n",
      "Epoch 298/500\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 38ms/step - loss: 0.0032\n",
      "Epoch 299/500\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 40ms/step - loss: 0.0032\n",
      "Epoch 300/500\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 42ms/step - loss: 0.0031\n",
      "Epoch 301/500\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 41ms/step - loss: 0.0030\n",
      "Epoch 302/500\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 38ms/step - loss: 0.0030\n",
      "Epoch 303/500\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 38ms/step - loss: 0.0029\n",
      "Epoch 304/500\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 38ms/step - loss: 0.0029\n",
      "Epoch 305/500\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 38ms/step - loss: 0.0028\n",
      "Epoch 306/500\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 38ms/step - loss: 0.0027\n",
      "Epoch 307/500\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 38ms/step - loss: 0.0027\n",
      "Epoch 308/500\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 38ms/step - loss: 0.0026\n",
      "Epoch 309/500\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 37ms/step - loss: 0.0026\n",
      "Epoch 310/500\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 37ms/step - loss: 0.0025\n",
      "Epoch 311/500\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 37ms/step - loss: 0.0025\n",
      "Epoch 312/500\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 39ms/step - loss: 0.0024\n",
      "Epoch 313/500\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 37ms/step - loss: 0.0024\n",
      "Epoch 314/500\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 38ms/step - loss: 0.0023\n",
      "Epoch 315/500\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 39ms/step - loss: 0.0023\n",
      "Epoch 316/500\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 37ms/step - loss: 0.0022\n",
      "Epoch 317/500\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 39ms/step - loss: 0.0022\n",
      "Epoch 318/500\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 39ms/step - loss: 0.0021\n",
      "Epoch 319/500\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 38ms/step - loss: 0.0021\n",
      "Epoch 320/500\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 37ms/step - loss: 0.0021\n",
      "Epoch 321/500\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 38ms/step - loss: 0.0020\n",
      "Epoch 322/500\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 40ms/step - loss: 0.0020\n",
      "Epoch 323/500\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 38ms/step - loss: 0.0019\n",
      "Epoch 324/500\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 40ms/step - loss: 0.0019\n",
      "Epoch 325/500\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 45ms/step - loss: 0.0019\n",
      "Epoch 326/500\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 39ms/step - loss: 0.0018\n",
      "Epoch 327/500\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 40ms/step - loss: 0.0018\n",
      "Epoch 328/500\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 39ms/step - loss: 0.0017\n",
      "Epoch 329/500\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 38ms/step - loss: 0.0017\n",
      "Epoch 330/500\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 37ms/step - loss: 0.0017\n",
      "Epoch 331/500\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 36ms/step - loss: 0.0016\n",
      "Epoch 332/500\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 39ms/step - loss: 0.0016\n",
      "Epoch 333/500\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 37ms/step - loss: 0.0016\n",
      "Epoch 334/500\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 37ms/step - loss: 0.0015\n",
      "Epoch 335/500\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 37ms/step - loss: 0.0015\n",
      "Epoch 336/500\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 37ms/step - loss: 0.0015\n",
      "Epoch 337/500\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 37ms/step - loss: 0.0014\n",
      "Epoch 338/500\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 37ms/step - loss: 0.0014\n",
      "Epoch 339/500\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 37ms/step - loss: 0.0014\n",
      "Epoch 340/500\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 37ms/step - loss: 0.0014\n",
      "Epoch 341/500\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 37ms/step - loss: 0.0013\n",
      "Epoch 342/500\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 37ms/step - loss: 0.0013\n",
      "Epoch 343/500\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 38ms/step - loss: 0.0013\n",
      "Epoch 344/500\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 37ms/step - loss: 0.0012\n",
      "Epoch 345/500\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 37ms/step - loss: 0.0012\n",
      "Epoch 346/500\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 37ms/step - loss: 0.0012\n",
      "Epoch 347/500\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 37ms/step - loss: 0.0012\n",
      "Epoch 348/500\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 37ms/step - loss: 0.0011\n",
      "Epoch 349/500\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 36ms/step - loss: 0.0011\n",
      "Epoch 350/500\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 37ms/step - loss: 0.0011\n",
      "Epoch 351/500\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 37ms/step - loss: 0.0011\n",
      "Epoch 352/500\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 37ms/step - loss: 0.0011\n",
      "Epoch 353/500\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 41ms/step - loss: 0.0010\n",
      "Epoch 354/500\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 38ms/step - loss: 0.0010\n",
      "Epoch 355/500\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 37ms/step - loss: 9.9315e-04\n",
      "Epoch 356/500\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 38ms/step - loss: 9.7275e-04\n",
      "Epoch 357/500\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 37ms/step - loss: 9.5277e-04\n",
      "Epoch 358/500\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 38ms/step - loss: 9.3320e-04\n",
      "Epoch 359/500\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 38ms/step - loss: 9.1403e-04\n",
      "Epoch 360/500\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 39ms/step - loss: 8.9526e-04\n",
      "Epoch 361/500\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 37ms/step - loss: 8.7687e-04\n",
      "Epoch 362/500\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 38ms/step - loss: 8.5886e-04\n",
      "Epoch 363/500\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 38ms/step - loss: 8.4122e-04\n",
      "Epoch 364/500\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 39ms/step - loss: 8.2394e-04\n",
      "Epoch 365/500\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 38ms/step - loss: 8.0702e-04\n",
      "Epoch 366/500\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 39ms/step - loss: 7.9044e-04\n",
      "Epoch 367/500\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 40ms/step - loss: 7.7420e-04\n",
      "Epoch 368/500\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 40ms/step - loss: 7.5830e-04\n",
      "Epoch 369/500\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 38ms/step - loss: 7.4272e-04\n",
      "Epoch 370/500\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 40ms/step - loss: 7.2747e-04\n",
      "Epoch 371/500\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 38ms/step - loss: 7.1253e-04\n",
      "Epoch 372/500\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 38ms/step - loss: 6.9789e-04\n",
      "Epoch 373/500\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 37ms/step - loss: 6.8356e-04\n",
      "Epoch 374/500\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 38ms/step - loss: 6.6952e-04\n",
      "Epoch 375/500\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 37ms/step - loss: 6.5576e-04\n",
      "Epoch 376/500\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 38ms/step - loss: 6.4229e-04\n",
      "Epoch 377/500\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 41ms/step - loss: 6.2910e-04\n",
      "Epoch 378/500\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 38ms/step - loss: 6.1617e-04\n",
      "Epoch 379/500\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 37ms/step - loss: 6.0352e-04\n",
      "Epoch 380/500\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 38ms/step - loss: 5.9112e-04\n",
      "Epoch 381/500\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 38ms/step - loss: 5.7898e-04\n",
      "Epoch 382/500\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 37ms/step - loss: 5.6709e-04\n",
      "Epoch 383/500\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 37ms/step - loss: 5.5544e-04\n",
      "Epoch 384/500\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 37ms/step - loss: 5.4403e-04\n",
      "Epoch 385/500\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 37ms/step - loss: 5.3285e-04\n",
      "Epoch 386/500\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 37ms/step - loss: 5.2191e-04\n",
      "Epoch 387/500\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 36ms/step - loss: 5.1119e-04\n",
      "Epoch 388/500\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 40ms/step - loss: 5.0069e-04\n",
      "Epoch 389/500\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 36ms/step - loss: 4.9041e-04\n",
      "Epoch 390/500\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 36ms/step - loss: 4.8033e-04\n",
      "Epoch 391/500\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 38ms/step - loss: 4.7047e-04\n",
      "Epoch 392/500\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 38ms/step - loss: 4.6080e-04\n",
      "Epoch 393/500\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 37ms/step - loss: 4.5134e-04\n",
      "Epoch 394/500\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 37ms/step - loss: 4.4207e-04\n",
      "Epoch 395/500\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 37ms/step - loss: 4.3299e-04\n",
      "Epoch 396/500\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 36ms/step - loss: 4.2409e-04\n",
      "Epoch 397/500\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 37ms/step - loss: 4.1538e-04\n",
      "Epoch 398/500\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 37ms/step - loss: 4.0685e-04\n",
      "Epoch 399/500\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 37ms/step - loss: 3.9849e-04\n",
      "Epoch 400/500\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 37ms/step - loss: 3.9031e-04\n",
      "Epoch 401/500\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 39ms/step - loss: 3.8229e-04\n",
      "Epoch 402/500\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 40ms/step - loss: 3.7444e-04\n",
      "Epoch 403/500\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 39ms/step - loss: 3.6675e-04\n",
      "Epoch 404/500\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 39ms/step - loss: 3.5921e-04\n",
      "Epoch 405/500\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 41ms/step - loss: 3.5184e-04\n",
      "Epoch 406/500\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 39ms/step - loss: 3.4461e-04\n",
      "Epoch 407/500\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 40ms/step - loss: 3.3753e-04\n",
      "Epoch 408/500\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 40ms/step - loss: 3.3060e-04\n",
      "Epoch 409/500\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 40ms/step - loss: 3.2380e-04\n",
      "Epoch 410/500\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 40ms/step - loss: 3.1715e-04\n",
      "Epoch 411/500\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 41ms/step - loss: 3.1064e-04\n",
      "Epoch 412/500\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 40ms/step - loss: 3.0426e-04\n",
      "Epoch 413/500\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 41ms/step - loss: 2.9801e-04\n",
      "Epoch 414/500\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 41ms/step - loss: 2.9189e-04\n",
      "Epoch 415/500\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 40ms/step - loss: 2.8589e-04\n",
      "Epoch 416/500\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 40ms/step - loss: 2.8002e-04\n",
      "Epoch 417/500\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 40ms/step - loss: 2.7427e-04\n",
      "Epoch 418/500\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 40ms/step - loss: 2.6863e-04\n",
      "Epoch 419/500\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 39ms/step - loss: 2.6312e-04\n",
      "Epoch 420/500\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 39ms/step - loss: 2.5771e-04\n",
      "Epoch 421/500\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 40ms/step - loss: 2.5242e-04\n",
      "Epoch 422/500\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 40ms/step - loss: 2.4723e-04\n",
      "Epoch 423/500\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 40ms/step - loss: 2.4215e-04\n",
      "Epoch 424/500\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 40ms/step - loss: 2.3718e-04\n",
      "Epoch 425/500\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 38ms/step - loss: 2.3231e-04\n",
      "Epoch 426/500\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 40ms/step - loss: 2.2754e-04\n",
      "Epoch 427/500\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[4], line 19\u001B[0m\n\u001B[1;32m     16\u001B[0m ys \u001B[38;5;241m=\u001B[39m np\u001B[38;5;241m.\u001B[39marray([\u001B[38;5;241m-\u001B[39m\u001B[38;5;241m3.0\u001B[39m, \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m1.0\u001B[39m, \u001B[38;5;241m1.0\u001B[39m, \u001B[38;5;241m3.0\u001B[39m, \u001B[38;5;241m5.0\u001B[39m, \u001B[38;5;241m7.0\u001B[39m], dtype\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mfloat\u001B[39m)  \u001B[38;5;66;03m# Corresponding outputs\u001B[39;00m\n\u001B[1;32m     18\u001B[0m \u001B[38;5;66;03m# Train the model\u001B[39;00m\n\u001B[0;32m---> 19\u001B[0m \u001B[43mmodel\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfit\u001B[49m\u001B[43m(\u001B[49m\u001B[43mxs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mys\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mepochs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m500\u001B[39;49m\u001B[43m)\u001B[49m  \u001B[38;5;66;03m# Train for 500 epochs to minimize loss\u001B[39;00m\n\u001B[1;32m     21\u001B[0m \u001B[38;5;66;03m# Use the model to predict a value\u001B[39;00m\n\u001B[1;32m     22\u001B[0m \u001B[38;5;28mprint\u001B[39m(model\u001B[38;5;241m.\u001B[39mpredict(np\u001B[38;5;241m.\u001B[39marray([\u001B[38;5;241m7.0\u001B[39m])))\n",
      "File \u001B[0;32m~/miniforge3/envs/ml/lib/python3.12/site-packages/keras/src/utils/traceback_utils.py:117\u001B[0m, in \u001B[0;36mfilter_traceback.<locals>.error_handler\u001B[0;34m(*args, **kwargs)\u001B[0m\n\u001B[1;32m    115\u001B[0m filtered_tb \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[1;32m    116\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m--> 117\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mfn\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    118\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mException\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m e:\n\u001B[1;32m    119\u001B[0m     filtered_tb \u001B[38;5;241m=\u001B[39m _process_traceback_frames(e\u001B[38;5;241m.\u001B[39m__traceback__)\n",
      "File \u001B[0;32m~/miniforge3/envs/ml/lib/python3.12/site-packages/keras/src/backend/tensorflow/trainer.py:366\u001B[0m, in \u001B[0;36mTensorFlowTrainer.fit\u001B[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq)\u001B[0m\n\u001B[1;32m    364\u001B[0m callbacks\u001B[38;5;241m.\u001B[39mon_epoch_begin(epoch)\n\u001B[1;32m    365\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m epoch_iterator\u001B[38;5;241m.\u001B[39mcatch_stop_iteration():\n\u001B[0;32m--> 366\u001B[0m \u001B[43m    \u001B[49m\u001B[38;5;28;43;01mfor\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43mstep\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43miterator\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;129;43;01min\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43mepoch_iterator\u001B[49m\u001B[43m:\u001B[49m\n\u001B[1;32m    367\u001B[0m \u001B[43m        \u001B[49m\u001B[43mcallbacks\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mon_train_batch_begin\u001B[49m\u001B[43m(\u001B[49m\u001B[43mstep\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    368\u001B[0m \u001B[43m        \u001B[49m\u001B[43mlogs\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mtrain_function\u001B[49m\u001B[43m(\u001B[49m\u001B[43miterator\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/miniforge3/envs/ml/lib/python3.12/site-packages/keras/src/backend/tensorflow/trainer.py:729\u001B[0m, in \u001B[0;36mTFEpochIterator.__next__\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m    728\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m__next__\u001B[39m(\u001B[38;5;28mself\u001B[39m):\n\u001B[0;32m--> 729\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mnext\u001B[39;49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_epoch_iterator\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/miniforge3/envs/ml/lib/python3.12/site-packages/keras/src/trainers/epoch_iterator.py:102\u001B[0m, in \u001B[0;36mEpochIterator._enumerate_iterator\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m    100\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m steps_per_epoch \u001B[38;5;241m>\u001B[39m \u001B[38;5;241m0\u001B[39m:\n\u001B[1;32m    101\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_current_iterator \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39msteps_per_epoch \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[0;32m--> 102\u001B[0m         \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_current_iterator \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43miter\u001B[39;49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_get_iterator\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    103\u001B[0m         \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_steps_seen \u001B[38;5;241m=\u001B[39m \u001B[38;5;241m0\u001B[39m\n\u001B[1;32m    104\u001B[0m     \u001B[38;5;28;01mfor\u001B[39;00m step \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mrange\u001B[39m(\u001B[38;5;241m0\u001B[39m, steps_per_epoch, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39msteps_per_execution):\n",
      "File \u001B[0;32m~/miniforge3/envs/ml/lib/python3.12/site-packages/tensorflow/python/data/ops/dataset_ops.py:501\u001B[0m, in \u001B[0;36mDatasetV2.__iter__\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m    499\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m context\u001B[38;5;241m.\u001B[39mexecuting_eagerly() \u001B[38;5;129;01mor\u001B[39;00m ops\u001B[38;5;241m.\u001B[39minside_function():\n\u001B[1;32m    500\u001B[0m   \u001B[38;5;28;01mwith\u001B[39;00m ops\u001B[38;5;241m.\u001B[39mcolocate_with(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_variant_tensor):\n\u001B[0;32m--> 501\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43miterator_ops\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mOwnedIterator\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m)\u001B[49m\n\u001B[1;32m    502\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m    503\u001B[0m   \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mRuntimeError\u001B[39;00m(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m`tf.data.Dataset` only supports Python-style \u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m    504\u001B[0m                      \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124miteration in eager mode or within tf.function.\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n",
      "File \u001B[0;32m~/miniforge3/envs/ml/lib/python3.12/site-packages/tensorflow/python/data/ops/iterator_ops.py:709\u001B[0m, in \u001B[0;36mOwnedIterator.__init__\u001B[0;34m(self, dataset, components, element_spec)\u001B[0m\n\u001B[1;32m    705\u001B[0m   \u001B[38;5;28;01mif\u001B[39;00m (components \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;129;01mor\u001B[39;00m element_spec \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m):\n\u001B[1;32m    706\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\n\u001B[1;32m    707\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mWhen `dataset` is provided, `element_spec` and `components` must \u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m    708\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mnot be specified.\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[0;32m--> 709\u001B[0m   \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_create_iterator\u001B[49m\u001B[43m(\u001B[49m\u001B[43mdataset\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    711\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_get_next_call_count \u001B[38;5;241m=\u001B[39m \u001B[38;5;241m0\u001B[39m\n",
      "File \u001B[0;32m~/miniforge3/envs/ml/lib/python3.12/site-packages/tensorflow/python/data/ops/iterator_ops.py:748\u001B[0m, in \u001B[0;36mOwnedIterator._create_iterator\u001B[0;34m(self, dataset)\u001B[0m\n\u001B[1;32m    745\u001B[0m   \u001B[38;5;28;01massert\u001B[39;00m \u001B[38;5;28mlen\u001B[39m(fulltype\u001B[38;5;241m.\u001B[39margs[\u001B[38;5;241m0\u001B[39m]\u001B[38;5;241m.\u001B[39margs[\u001B[38;5;241m0\u001B[39m]\u001B[38;5;241m.\u001B[39margs) \u001B[38;5;241m==\u001B[39m \u001B[38;5;28mlen\u001B[39m(\n\u001B[1;32m    746\u001B[0m       \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_flat_output_types)\n\u001B[1;32m    747\u001B[0m   \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_iterator_resource\u001B[38;5;241m.\u001B[39mop\u001B[38;5;241m.\u001B[39mexperimental_set_type(fulltype)\n\u001B[0;32m--> 748\u001B[0m \u001B[43mgen_dataset_ops\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mmake_iterator\u001B[49m\u001B[43m(\u001B[49m\u001B[43mds_variant\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_iterator_resource\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/miniforge3/envs/ml/lib/python3.12/site-packages/tensorflow/python/ops/gen_dataset_ops.py:3478\u001B[0m, in \u001B[0;36mmake_iterator\u001B[0;34m(dataset, iterator, name)\u001B[0m\n\u001B[1;32m   3476\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m tld\u001B[38;5;241m.\u001B[39mis_eager:\n\u001B[1;32m   3477\u001B[0m   \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m-> 3478\u001B[0m     _result \u001B[38;5;241m=\u001B[39m \u001B[43mpywrap_tfe\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mTFE_Py_FastPathExecute\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m   3479\u001B[0m \u001B[43m      \u001B[49m\u001B[43m_ctx\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mMakeIterator\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mname\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdataset\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43miterator\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   3480\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m _result\n\u001B[1;32m   3481\u001B[0m   \u001B[38;5;28;01mexcept\u001B[39;00m _core\u001B[38;5;241m.\u001B[39m_NotOkStatusException \u001B[38;5;28;01mas\u001B[39;00m e:\n",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "execution_count": 4
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "Episode 2: Computer vision by building a neural network with TensorFlow.\n",
    "What is computer vision? Computer vision is a branch of AI that allows computers to interpret and analyze visual data like images and videos, replicating human vision capabilities. It uses techniques like machine learning and deep learning to recognize objects, detect patterns, and understand pixels. Applications include face recognition, self-driving cars, medical imaging, and augmented reality.\n",
    "When you have an image, you have to give it an id so that a computer can know which image is which but when you are doing this, you have to give it a number id instead of a string id so that there is no english bias:\n",
    "![](ImageID.png)\n",
    "Now, here is the exercise for the Mnist fashion data set: https://colab.research.google.com/github/lmoroney/dlaicourse/blob/master/Exercises/Exercise%202%20-%20Handwriting%20Recognition/Exercise2-Question.ipynbThis\n",
    "now below is the code for a computer vision model that uses the mnist data set to have the computer figure out where to place what items into 1 of the 10 categories of clothing:"
   ],
   "id": "5c22f7f39f90c487"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-10T16:43:38.342131Z",
     "start_time": "2024-12-09T00:55:46.279756Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import tensorflow as tf\n",
    "# imports tensorflow\n",
    "mnist = tf.keras.datasets.mnist\n",
    "# loading in the mnist dataset\n",
    "\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "# Loads in the training and testing images.\n",
    "\n",
    "\n",
    "x_train, x_test = x_train / 255.0, x_test / 255.0\n",
    "# normalize data value's between 1 and 0\n",
    "\n",
    "\n",
    "model = tf.keras.models.Sequential([\n",
    "    # This initializes a sequential model, which is a linear stack of layers. It allows you to define a simple feed-forward neural network by adding layers one after another.\n",
    "    tf.keras.layers.Flatten(input_shape=(28, 28)),\n",
    "    #The Flatten layer reshapes the 2D input images (28x28 pixels) into a 1D array of 784 elements. This is necessary to pass the data to fully connected (dense) layers. The input_shape=(28, 28) specifies the shape of the input images.\n",
    "    tf.keras.layers.Dense(128, activation='relu'),\n",
    "    #This is a fully connected (dense) layer with 128 neurons. Each neuron is connected to all neurons in the previous layer. The activation function used is ReLU (Rectified Linear Unit), if a number is less than zero it turns to zero and otherwise the number keeps it size\n",
    "\n",
    "    tf.keras.layers.Dense(10, activation='softmax')\n",
    "    #This is another dense layer with 10 neurons, corresponding to the number of output classes (e.g., digits 0-9 if working with MNIST). The softmax activation function ensures that the outputs are probabilities that sum to 1, which is ideal for multi-class classification. sets the largest to 1 and the rest to 0.\n",
    "\n",
    "\n",
    "\n",
    "])\n",
    "\n",
    "model.compile(optimizer='adam',\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "# This compiles the model, specifying the optimizer and loss function.\n",
    "# The optimizer='adam' uses the Adam optimization algorithm, which combines the benefits of RMSProp and momentum-based gradient descent.\n",
    "# The loss='sparse_categorical_crossentropy' is used for multi-class classification tasks with integer-encoded labels.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "model.fit(x_train, y_train, epochs=5)\n",
    "#This trains the model on the train_images and train_labels dataset for 5 epochs (iterations over the full dataset). During training, the model adjusts its weights to minimize the loss function.\n",
    "# Evaluate the model on test data\n",
    "test_loss, test_acc = model.evaluate(x_test, y_test)\n",
    "# This evaluates the trained model on the test dataset (test_images and test_labels), returning the loss (test_loss) and accuracy (test_acc). This helps to assess how well the model generalizes to unseen data.\n",
    "\n",
    "print(f\"Test accuracy: {test_acc}\")\n",
    "# prints test accuracy\n"
   ],
   "id": "fa417e35cd320be4",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "\u001B[1m1875/1875\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m4s\u001B[0m 2ms/step - accuracy: 0.8726 - loss: 0.4439\n",
      "Epoch 2/5\n",
      "\u001B[1m1875/1875\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m3s\u001B[0m 2ms/step - accuracy: 0.9640 - loss: 0.1234\n",
      "Epoch 3/5\n",
      "\u001B[1m1875/1875\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m3s\u001B[0m 2ms/step - accuracy: 0.9759 - loss: 0.0815\n",
      "Epoch 4/5\n",
      "\u001B[1m1875/1875\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m3s\u001B[0m 2ms/step - accuracy: 0.9821 - loss: 0.0589\n",
      "Epoch 5/5\n",
      "\u001B[1m1875/1875\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m3s\u001B[0m 2ms/step - accuracy: 0.9872 - loss: 0.0442\n",
      "\u001B[1m313/313\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 1ms/step - accuracy: 0.9728 - loss: 0.0878\n",
      "Test accuracy: 0.9779000282287598\n"
     ]
    }
   ],
   "execution_count": 4
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "Episode 3 & 4: Convolutions and Pooling:\n",
    "what is a convolution?\n",
    "A convolution is a filter that is used in machine learning and computer vision. With convolutions we are able to process a image down to its bare features that will match the labels. using many random values in filters we can find the best filter to match the image to the label to.\n",
    "what is pooling?: Pooling is a way to decrease the resolution of an image without actually damaging its integrity and makes it lighter for the program to handle and make it learn much faster.\n",
    "How does it work though?:\n",
    "Pooling: For every 2x2 pixels, it takes the one with the darkest value and it replaces the 4 pixels with a pixel of the darkest value.\n",
    "![](PoolingExplained.png)\n",
    "![](PoolingCode.png)\n",
    "Convolutions: We take 3x3 pixels from an image, then we define a 3x3 filter with specific values to multiply the images value, giving us a new image that has been filtered.\n",
    "![](ConvolutionsExplained.png)\n",
    "![](ConvolutionsCode.png)\n",
    "Now, there is one last lesson we are gonna learn, What looks Wrong in this code:\n",
    "![](26x26Code.png)\n",
    "It shows that the convolutions are 26x26 rather than 28x28? You may think that his is wrong but it is actually not, as when you are doing convolutions with an image, you can only apply this filter away from the edge so it does not mess up because of the empty parts outside of the image.\n",
    "Here is the Exercise for pooling and convolutions: https://colab.research.google.com/github/lmoroney/dlaicourse/blob/master/Exercises/Exercise%203%20-%20Convolutions/Exercise%203%20-%20Question.ipynb\n",
    "\n",
    "Mnist Code improved using convolutions and pooling:\n",
    "\n"
   ],
   "id": "d977fece8d7820d1"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-10T16:43:38.378401Z",
     "start_time": "2024-12-09T21:13:26.880926Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "# Load the MNIST dataset\n",
    "mnist = tf.keras.datasets.mnist\n",
    "(training_images, training_labels), (test_images, test_labels) = mnist.load_data()\n",
    "\n",
    "# Normalize the pixel values to the range 0-1\n",
    "training_images = training_images / 255.0\n",
    "test_images = test_images / 255.0\n",
    "\n",
    "# Reshape the data to add a channel dimension (required for Conv2D)\n",
    "training_images = training_images.reshape(-1, 28, 28, 1)\n",
    "test_images = test_images.reshape(-1, 28, 28, 1)\n",
    "\n",
    "# Define the model\n",
    "model = tf.keras.models.Sequential([\n",
    "    # First convolutional layer with pooling\n",
    "    tf.keras.layers.Conv2D(32, (3, 3), activation='relu', input_shape=(28, 28, 1)),\n",
    "    tf.keras.layers.MaxPooling2D(2, 2),\n",
    "\n",
    "    # Second convolutional layer with pooling\n",
    "    tf.keras.layers.Conv2D(64, (3, 3), activation='relu'),\n",
    "    tf.keras.layers.MaxPooling2D(2, 2),\n",
    "\n",
    "    # Flatten the output\n",
    "    tf.keras.layers.Flatten(),\n",
    "\n",
    "    # Fully connected dense layer\n",
    "    tf.keras.layers.Dense(128, activation='relu'),\n",
    "\n",
    "    # Output layer with 10 classes\n",
    "    tf.keras.layers.Dense(10, activation='softmax')\n",
    "])\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam',\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# Train the model\n",
    "model.fit(training_images, training_labels, epochs=5)\n",
    "\n",
    "# Evaluate the model\n",
    "test_loss, test_accuracy = model.evaluate(test_images, test_labels)\n",
    "print(f\"Test accuracy: {test_accuracy}\")\n"
   ],
   "id": "7c0320ca703c1dc1",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-12-09 16:13:27.768530: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: SSE4.1 SSE4.2 AVX AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "/Users/anton/miniforge3/envs/ml/lib/python3.12/site-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "\u001B[1m1875/1875\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m29s\u001B[0m 15ms/step - accuracy: 0.9048 - loss: 0.3019\n",
      "Epoch 2/5\n",
      "\u001B[1m1875/1875\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m40s\u001B[0m 15ms/step - accuracy: 0.9871 - loss: 0.0427\n",
      "Epoch 3/5\n",
      "\u001B[1m1875/1875\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m28s\u001B[0m 15ms/step - accuracy: 0.9918 - loss: 0.0271\n",
      "Epoch 4/5\n",
      "\u001B[1m1875/1875\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m28s\u001B[0m 15ms/step - accuracy: 0.9934 - loss: 0.0191\n",
      "Epoch 5/5\n",
      "\u001B[1m1875/1875\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m29s\u001B[0m 16ms/step - accuracy: 0.9954 - loss: 0.0152\n",
      "\u001B[1m313/313\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 3ms/step - accuracy: 0.9872 - loss: 0.0463\n",
      "Test accuracy: 0.9900000095367432\n"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Wow! Using Convolutions and Pooling that was a lot more accurate! But it did take a quiet longer and put a much bigger strain on my computer compared to the other one without pooling or convolutions.",
   "id": "97597554d346ace8"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "Episode 5&6: Real-world image classification using convolutional neural networks\n",
    "Ok before we build our model that deals with more complex images, we first gotta learn some new stuff:\n",
    "When we have multiple categories of images we want to store and use, how do we efficiently store all of these images into categories? simple, we create a generator:\n",
    "![](Generator.png)\n",
    "using a generator you can have tensor flow automatically name a label based off of the directory.\n",
    "here is the Exercise for a CNN that tells the difference between a horse and a human: https://colab.research.google.com/github/lmoroney/dlaicourse/blob/master/Exercises/Exercise%204%20-%20Handling%20Complex%20Images/Exercise%204-Question.ipynb\n",
    "Now we will examine the code for a CNN that uses a generator to tell the difference between a human and a horse:\n"
   ],
   "id": "9eb360b2bf01ec82"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-10T16:43:38.386320Z",
     "start_time": "2024-12-09T21:43:33.005334Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import tensorflow as tf  # TensorFlow is a library for deep learning and we’ll use it to build our model\n",
    "import os  # Provides utilities to interact with the operating system\n",
    "import zipfile  # Helps us work with ZIP files\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator  # Prepares our images for training\n",
    "\n",
    "DESIRED_ACCURACY = 0.999  # This is the accuracy we want the model to achieve before stopping training\n",
    "\n",
    "# Download the dataset and save it locally\n",
    "!wget --no-check-certificate \\\n",
    "\"https://storage.googleapis.com/learning-datasets/happy-or-sad.zip\" \\\n",
    "-O \"/tmp/happy-or-sad.zip\"\n",
    "\n",
    "# Unzip the downloaded file into a folder so we can access the images\n",
    "zip_ref = zipfile.ZipFile(\"/tmp/happy-or-sad.zip\", 'r')  # Open the zip file\n",
    "zip_ref.extractall(\"/tmp/h-or-s\")  # Extract the contents to this folder\n",
    "zip_ref.close()  # Close the zip file\n",
    "\n",
    "# Define a custom callback that stops training once the desired accuracy is reached\n",
    "class myCallback(tf.keras.callbacks.Callback):  # We're subclassing the Callback class from TensorFlow\n",
    "    def on_epoch_end(self, epoch, logs=None):  # This runs at the end of every epoch\n",
    "        if logs.get('accuracy') >= DESIRED_ACCURACY:  # Check if the accuracy meets our threshold\n",
    "            print(\"\\nReached 99.9% accuracy so cancelling training!\")  # Print a message to notify us\n",
    "            self.model.stop_training = True  # Stop training if the condition is met\n",
    "\n",
    "callbacks = myCallback()  # Create an instance of our custom callback\n",
    "\n",
    "# Create an ImageDataGenerator to load and preprocess our images\n",
    "train_datagen = ImageDataGenerator(rescale=1.0/255.0)  # Rescale image pixel values to range [0, 1] for normalization\n",
    "\n",
    "# Load images from the directory and prepare them for training\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "    '/tmp/h-or-s',  # Path to the folder with training images\n",
    "    target_size=(150, 150),  # Resize all images to 150x150 pixels\n",
    "    batch_size=10,  # Load 10 images at a time for training\n",
    "    class_mode='binary'  # We’re doing binary classification (happy or sad)\n",
    ")\n",
    "\n",
    "# Define the model architecture\n",
    "model = tf.keras.models.Sequential([  # Sequential lets us stack layers in order\n",
    "    tf.keras.layers.Conv2D(16, (3, 3), activation='relu', input_shape=(150, 150, 3)),\n",
    "    # A convolutional layer with 16 filters, a 3x3 kernel, ReLU activation, and input size of 150x150x3 (RGB)\n",
    "\n",
    "    tf.keras.layers.MaxPooling2D(2, 2),\n",
    "    # A pooling layer that reduces image size by taking the maximum value in a 2x2 window (down-sampling)\n",
    "\n",
    "    tf.keras.layers.Conv2D(32, (3, 3), activation='relu'),\n",
    "    # Another convolutional layer, but now with 32 filters for extracting more complex features\n",
    "\n",
    "    tf.keras.layers.MaxPooling2D(2, 2),\n",
    "    # Pooling again to further reduce the image size while keeping important features\n",
    "\n",
    "    tf.keras.layers.Conv2D(64, (3, 3), activation='relu'),\n",
    "    # A third convolutional layer with 64 filters for even deeper feature extraction\n",
    "\n",
    "    tf.keras.layers.MaxPooling2D(2, 2),\n",
    "    # And another pooling layer to continue down-sampling the feature maps\n",
    "\n",
    "    tf.keras.layers.Flatten(),\n",
    "    # Flatten the output from the convolutional layers to prepare it for the dense layers\n",
    "\n",
    "    tf.keras.layers.Dense(512, activation='relu'),\n",
    "    # A fully connected dense layer with 512 neurons and ReLU activation to learn non-linear patterns\n",
    "\n",
    "    tf.keras.layers.Dense(1, activation='sigmoid')\n",
    "    # The final output layer with a single neuron and sigmoid activation, because it's binary classification\n",
    "])\n",
    "\n",
    "# Compile the model with an optimizer, loss function, and evaluation metric\n",
    "model.compile(\n",
    "    loss='binary_crossentropy',  # Loss function for binary classification problems\n",
    "    optimizer=tf.keras.optimizers.RMSprop(learning_rate=0.001),  # RMSprop optimizer with a learning rate of 0.001\n",
    "    metrics=['accuracy']  # Track accuracy as the evaluation metric during training\n",
    ")\n",
    "\n",
    "# Train the model using the prepared data\n",
    "history = model.fit(\n",
    "    train_generator,  # The training data generator\n",
    "    steps_per_epoch=8,  # Total number of steps (batches) per epoch (80 images / batch size of 10)\n",
    "    epochs=20,  # Train for a maximum of 20 epochs\n",
    "    callbacks=[callbacks]  # Use our custom callback to stop training when desired accuracy is reached\n",
    ")\n"
   ],
   "id": "a8b58e31c31344eb",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "zsh:1: command not found: wget\r\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '/tmp/happy-or-sad.zip'",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mFileNotFoundError\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[3], line 12\u001B[0m\n\u001B[1;32m      9\u001B[0m get_ipython()\u001B[38;5;241m.\u001B[39msystem(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mwget --no-check-certificate  \u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mhttps://storage.googleapis.com/learning-datasets/happy-or-sad.zip\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m  -\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m/tmp/happy-or-sad.zip\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m'\u001B[39m)\n\u001B[1;32m     11\u001B[0m \u001B[38;5;66;03m# Unzip the downloaded file into a folder so we can access the images\u001B[39;00m\n\u001B[0;32m---> 12\u001B[0m zip_ref \u001B[38;5;241m=\u001B[39m \u001B[43mzipfile\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mZipFile\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43m/tmp/happy-or-sad.zip\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mr\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m)\u001B[49m  \u001B[38;5;66;03m# Open the zip file\u001B[39;00m\n\u001B[1;32m     13\u001B[0m zip_ref\u001B[38;5;241m.\u001B[39mextractall(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m/tmp/h-or-s\u001B[39m\u001B[38;5;124m\"\u001B[39m)  \u001B[38;5;66;03m# Extract the contents to this folder\u001B[39;00m\n\u001B[1;32m     14\u001B[0m zip_ref\u001B[38;5;241m.\u001B[39mclose()  \u001B[38;5;66;03m# Close the zip file\u001B[39;00m\n",
      "File \u001B[0;32m~/miniforge3/envs/ml/lib/python3.12/zipfile/__init__.py:1331\u001B[0m, in \u001B[0;36mZipFile.__init__\u001B[0;34m(self, file, mode, compression, allowZip64, compresslevel, strict_timestamps, metadata_encoding)\u001B[0m\n\u001B[1;32m   1329\u001B[0m \u001B[38;5;28;01mwhile\u001B[39;00m \u001B[38;5;28;01mTrue\u001B[39;00m:\n\u001B[1;32m   1330\u001B[0m     \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m-> 1331\u001B[0m         \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mfp \u001B[38;5;241m=\u001B[39m \u001B[43mio\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mopen\u001B[49m\u001B[43m(\u001B[49m\u001B[43mfile\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mfilemode\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1332\u001B[0m     \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mOSError\u001B[39;00m:\n\u001B[1;32m   1333\u001B[0m         \u001B[38;5;28;01mif\u001B[39;00m filemode \u001B[38;5;129;01min\u001B[39;00m modeDict:\n",
      "\u001B[0;31mFileNotFoundError\u001B[0m: [Errno 2] No such file or directory: '/tmp/happy-or-sad.zip'"
     ]
    }
   ],
   "execution_count": 3
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "\n",
    "now we will get into a even harder challenge, a cat or dog CNN, here is the dataset:\n",
    "https://www.kaggle.com/c/dogs-vs-cats/data\n",
    ",here is the exercise: https://colab.research.google.com/github/lmoroney/mlday-tokyo/blob/master/Lab6-Cats-v-Dogs.ipynb#scrollTo=7v55rWlQehzL\n",
    "and here is the answer:"
   ],
   "id": "e2d65f61115bae01"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "import os\n",
    "\n",
    "# Load the dataset\n",
    "!wget --no-check-certificate \\\n",
    "\"https://storage.googleapis.com/mledu-datasets/cats_and_dogs_filtered.zip\" \\\n",
    "-O \"/tmp/cats_and_dogs_filtered.zip\"\n",
    "\n",
    "# Unzip the dataset\n",
    "import zipfile\n",
    "local_zip = '/tmp/cats_and_dogs_filtered.zip'\n",
    "zip_ref = zipfile.ZipFile(local_zip, 'r')\n",
    "zip_ref.extractall('/tmp')\n",
    "zip_ref.close()\n",
    "\n",
    "# Define paths for training and validation directories\n",
    "base_dir = '/tmp/cats_and_dogs_filtered'\n",
    "train_dir = os.path.join(base_dir, 'train')\n",
    "validation_dir = os.path.join(base_dir, 'validation')\n",
    "\n",
    "# Training and validation subdirectories for cats and dogs\n",
    "train_cats_dir = os.path.join(train_dir, 'cats')\n",
    "train_dogs_dir = os.path.join(train_dir, 'dogs')\n",
    "validation_cats_dir = os.path.join(validation_dir, 'cats')\n",
    "validation_dogs_dir = os.path.join(validation_dir, 'dogs')\n",
    "\n",
    "# Define a data generator for training and validation\n",
    "train_datagen = ImageDataGenerator(rescale=1.0/255.0)  # Normalize pixel values to [0, 1]\n",
    "validation_datagen = ImageDataGenerator(rescale=1.0/255.0)\n",
    "\n",
    "# Flow training images in batches of 20 using train_datagen\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "    train_dir,               # Training directory path\n",
    "    target_size=(150, 150),  # Resize all images to 150x150\n",
    "    batch_size=20,           # Batch size\n",
    "    class_mode='binary'      # Binary classification (cats and dogs)\n",
    ")\n",
    "\n",
    "# Flow validation images in batches of 20 using validation_datagen\n",
    "validation_generator = validation_datagen.flow_from_directory(\n",
    "    validation_dir,\n",
    "    target_size=(150, 150),\n",
    "    batch_size=20,\n",
    "    class_mode='binary'\n",
    ")\n",
    "\n",
    "# Define the CNN model\n",
    "model = tf.keras.models.Sequential([\n",
    "    tf.keras.layers.Conv2D(32, (3, 3), activation='relu', input_shape=(150, 150, 3)),\n",
    "    tf.keras.layers.MaxPooling2D(2, 2),\n",
    "    tf.keras.layers.Conv2D(64, (3, 3), activation='relu'),\n",
    "    tf.keras.layers.MaxPooling2D(2, 2),\n",
    "    tf.keras.layers.Conv2D(128, (3, 3), activation='relu'),\n",
    "    tf.keras.layers.MaxPooling2D(2, 2),\n",
    "    tf.keras.layers.Flatten(),\n",
    "    tf.keras.layers.Dense(512, activation='relu'),\n",
    "    tf.keras.layers.Dense(1, activation='sigmoid')  # Single output node for binary classification\n",
    "])\n",
    "\n",
    "# Compile the model\n",
    "model.compile(\n",
    "    loss='binary_crossentropy',            # Binary crossentropy for binary classification\n",
    "    optimizer=tf.keras.optimizers.RMSprop(learning_rate=0.001),  # Optimizer\n",
    "    metrics=['accuracy']                   # Track accuracy during training\n",
    ")\n",
    "\n",
    "# Train the model\n",
    "history = model.fit(\n",
    "    train_generator,\n",
    "    steps_per_epoch=100,       # Number of batches per epoch\n",
    "    epochs=15,                 # Number of epochs to train\n",
    "    validation_data=validation_generator,\n",
    "    validation_steps=50        # Number of batches for validation\n",
    ")\n",
    "\n",
    "# Evaluate the model\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Plot training and validation accuracy over epochs\n",
    "acc = history.history['accuracy']\n",
    "val_acc = history.history['val_accuracy']\n",
    "loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "\n",
    "epochs = range(len(acc))\n",
    "\n",
    "plt.plot(epochs, acc, 'r', label='Training Accuracy')\n",
    "plt.plot(epochs, val_acc, 'b', label='Validation Accuracy')\n",
    "plt.title('Training and Validation Accuracy')\n",
    "plt.legend(loc=0)\n",
    "plt.show()\n",
    "\n",
    "plt.plot(epochs, loss, 'r', label='Training Loss')\n",
    "plt.plot(epochs, val_loss, 'b', label='Validation Loss')\n",
    "plt.title('Training and Validation Loss')\n",
    "plt.legend(loc=0)\n",
    "plt.show()\n"
   ],
   "id": "e85bc2e2f10220e4"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "Episodes 7: Image Augmentation and Overfitting.\n",
    "What is overfitting? Overfitting occurs when a model learns the training data too well, including its noise and specific patterns, resulting in poor generalization to new, unseen data. This happens when the model is too complex (e.g., too many parameters) for the amount of training data or lacks proper regularization.\n",
    "now what is image augmentation? Image augmentation is when we use a ImageDataGenerator to change an image into something else, this helps to stop overfitting and here is the exercise:\n",
    "https://colab.research.google.com/github/lmoroney/dlaicourse/blob/master/Course%202%20-%20Part%204%20-%20Lesson%202%20-%20Notebook%20(Cats%20v%20Dogs%20Augmentation).ipynb\n",
    "And here is the code for a CNN that uses a ImageDataGenerator:"
   ],
   "id": "5cb789343e8cd03d"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Import necessary libraries\n",
    "import os  # For working with file paths\n",
    "import zipfile  # To unzip the downloaded dataset\n",
    "import tensorflow as tf  # TensorFlow for building and training the model\n",
    "from tensorflow.keras.optimizers import RMSprop  # RMSprop optimizer for training\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator  # For preprocessing and augmenting images\n",
    "\n",
    "# Download the dataset of cats and dogs and save it to a temporary directory\n",
    "!wget --no-check-certificate \\\n",
    "https://storage.googleapis.com/mledu-datasets/cats_and_dogs_filtered.zip \\\n",
    "        -O /tmp/cats_and_dogs_filtered.zip\n",
    "\n",
    "# Define the path to the downloaded zip file\n",
    "local_zip = '/tmp/cats_and_dogs_filtered.zip'\n",
    "\n",
    "# Extract the contents of the zip file\n",
    "zip_ref = zipfile.ZipFile(local_zip, 'r')  # Open the zip file for reading\n",
    "zip_ref.extractall('/tmp')  # Extract all files to the '/tmp' directory\n",
    "zip_ref.close()  # Close the zip file after extracting\n",
    "\n",
    "# Define the base directory for the dataset\n",
    "base_dir = '/tmp/cats_and_dogs_filtered'\n",
    "\n",
    "# Set paths to training and validation directories\n",
    "train_dir = os.path.join(base_dir, 'train')  # Directory containing training data\n",
    "validation_dir = os.path.join(base_dir, 'validation')  # Directory containing validation data\n",
    "\n",
    "# Define paths for subdirectories of training and validation data\n",
    "train_cats_dir = os.path.join(train_dir, 'cats')  # Training images of cats\n",
    "train_dogs_dir = os.path.join(train_dir, 'dogs')  # Training images of dogs\n",
    "validation_cats_dir = os.path.join(validation_dir, 'cats')  # Validation images of cats\n",
    "validation_dogs_dir = os.path.join(validation_dir, 'dogs')  # Validation images of dogs\n",
    "\n",
    "# Define the CNN model\n",
    "model = tf.keras.models.Sequential([  # Sequential model allows stacking layers\n",
    "    tf.keras.layers.Conv2D(32, (3, 3), activation='relu', input_shape=(150, 150, 3)),\n",
    "    # Convolutional layer with 32 filters, 3x3 kernel size, ReLU activation, and input size of 150x150x3 (RGB images)\n",
    "    tf.keras.layers.MaxPooling2D(2, 2),  # Max pooling layer to reduce spatial dimensions\n",
    "\n",
    "    tf.keras.layers.Conv2D(64, (3, 3), activation='relu'),\n",
    "    # Second convolutional layer with 64 filters\n",
    "    tf.keras.layers.MaxPooling2D(2, 2),  # Pooling to further downsample the image\n",
    "\n",
    "    tf.keras.layers.Conv2D(128, (3, 3), activation='relu'),\n",
    "    # Third convolutional layer with 128 filters\n",
    "    tf.keras.layers.MaxPooling2D(2, 2),  # Pooling again\n",
    "\n",
    "    tf.keras.layers.Conv2D(128, (3, 3), activation='relu'),\n",
    "    # Fourth convolutional layer with 128 filters\n",
    "    tf.keras.layers.MaxPooling2D(2, 2),  # Pooling again\n",
    "\n",
    "    tf.keras.layers.Dropout(0.5),  # Dropout to reduce overfitting by randomly setting 50% of neurons to 0\n",
    "\n",
    "    tf.keras.layers.Flatten(),  # Flatten layer to convert 3D feature maps to 1D vector\n",
    "\n",
    "    tf.keras.layers.Dense(512, activation='relu'),\n",
    "    # Dense layer with 512 neurons for learning high-level features\n",
    "\n",
    "    tf.keras.layers.Dense(1, activation='sigmoid')\n",
    "    # Output layer with 1 neuron and sigmoid activation for binary classification\n",
    "])\n",
    "\n",
    "# Compile the model\n",
    "model.compile(\n",
    "    loss='binary_crossentropy',  # Binary cross-entropy loss for binary classification\n",
    "    optimizer=RMSprop(learning_rate=1e-4),  # RMSprop optimizer with a learning rate of 0.0001\n",
    "    metrics=['accuracy']  # Track accuracy during training\n",
    ")\n",
    "\n",
    "# Define a data generator for training with data augmentation\n",
    "train_datagen = ImageDataGenerator(\n",
    "    rescale=1.0/255,  # Normalize pixel values to the range [0, 1]\n",
    "    rotation_range=40,  # Randomly rotate images by up to 40 degrees\n",
    "    width_shift_range=0.2,  # Randomly shift images horizontally by up to 20% of width\n",
    "    height_shift_range=0.2,  # Randomly shift images vertically by up to 20% of height\n",
    "    shear_range=0.2,  # Apply random shearing transformations\n",
    "    zoom_range=0.2,  # Randomly zoom in/out by up to 20%\n",
    "    horizontal_flip=True,  # Randomly flip images horizontally\n",
    "    fill_mode='nearest'  # Fill any gaps created by transformations with the nearest pixel value\n",
    ")\n",
    "\n",
    "# Define a data generator for validation without augmentation\n",
    "test_datagen = ImageDataGenerator(rescale=1.0/255)  # Only normalize pixel values\n",
    "\n",
    "# Create a generator for training data\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "    train_dir,  # Source directory for training images\n",
    "    target_size=(150, 150),  # Resize all images to 150x150 pixels\n",
    "    batch_size=20,  # Load images in batches of 20\n",
    "    class_mode='binary'  # Binary classification (cats or dogs)\n",
    ")\n",
    "\n",
    "# Create a generator for validation data\n",
    "validation_generator = test_datagen.flow_from_directory(\n",
    "    validation_dir,  # Source directory for validation images\n",
    "    target_size=(150, 150),  # Resize all images to 150x150 pixels\n",
    "    batch_size=20,  # Load images in batches of 20\n",
    "    class_mode='binary'  # Binary classification\n",
    ")\n",
    "\n",
    "# Train the model\n",
    "history = model.fit(\n",
    "    train_generator,  # Training data generator\n",
    "    steps_per_epoch=100,  # Number of training batches per epoch (2000 images / 20 images per batch)\n",
    "    epochs=100,  # Train the model for 100 epochs\n",
    "    validation_data=validation_generator,  # Validation data generator\n",
    "    validation_steps=50,  # Number of validation batches per epoch (1000 images / 20 images per batch)\n",
    "    verbose=2  # Print detailed logs during training\n",
    ")\n"
   ],
   "id": "55ed5f4c8e059472"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "Episodes 8 & 9 & 10: Tokenizers and Using Sequencing API's in TensorFlow.\n",
    "When creating a program that recognizes words we Use word-based encoding and ASCII:\n",
    "Word-based encoding: for each new word in a sentence we give it a value so that the computer understands better the difference between 2 sentences.\n",
    "ASCII: a common coding format where letters and sounds are assigned a number from 0 to 255\n",
    "so we get something like this: output:{'i': 1, 'love': 2, 'my': 3, 'dog': 4, 'cat': 5}\n",
    "using this we can have it create a sentence like this: 1,2,3,5(i love my cat)\n",
    "Now here is an example in code format: https://colab.research.google.com/github/lmoroney/dlaicourse/blob/master/TensorFlow%20In%20Practice/Course%203%20-%20NLP/Course%203%20-%20Week%201%20-%20Lesson%201.ipynb#scrollTo=zaCMcjMQifQc or right here:\n"
   ],
   "id": "77d0908178e76152"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "\n",
    "# List of sentences to tokenize\n",
    "sentences = [\n",
    "    'i love my dog',\n",
    "    'I, love my cat',\n",
    "    'You love my dog!'\n",
    "]\n",
    "\n",
    "# Create a Tokenizer object with a vocabulary size limit of 100\n",
    "tokenizer = Tokenizer(num_words=100)  # num_words limits the vocab to the top 100 most frequent words\n",
    "\n",
    "# Fit the tokenizer on the sentences (build the word index)\n",
    "tokenizer.fit_on_texts(sentences)\n",
    "\n",
    "# Retrieve the word index generated by the tokenizer\n",
    "word_index = tokenizer.word_index\n",
    "\n",
    "# Print the word index\n",
    "print(word_index)\n"
   ],
   "id": "a4663716c8b0d27a"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "Now we also gotta learn something else, what is padding?\n",
    "Padding is the process of adding extra values (usually zeros) to sequences to make them all the same length. Now here is a example of a Tokenizer that uses padding: https://colab.research.google.com/github/lmoroney/dlaicourse/blob/master/TensorFlow%20In%20Practice/Course%203%20-%20NLP/Course%203%20-%20Week%201%20-%20Lesson%202.ipynb#scrollTo=ArOPfBwyZtln or right here:\n"
   ],
   "id": "9e6006641f2dad7e"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "# List of sentences to tokenize\n",
    "sentences = [\n",
    "    'I love my dog',\n",
    "    'I love my cat',\n",
    "    'You love my dog!',\n",
    "    'Do you think my dog is amazing?'\n",
    "]\n",
    "\n",
    "# Create a tokenizer with a vocabulary size of 100 and an out-of-vocabulary (OOV) token\n",
    "tokenizer = Tokenizer(num_words=100, oov_token=\"<OOV>\")\n",
    "tokenizer.fit_on_texts(sentences)  # Fit the tokenizer on the input sentences to build the word index\n",
    "\n",
    "word_index = tokenizer.word_index  # Retrieve the word index (mapping of words to integers)\n",
    "sequences = tokenizer.texts_to_sequences(sentences)  # Convert sentences into sequences of integers\n",
    "\n",
    "# Pad the sequences to a maximum length of 5 (shorter sequences are left-padded with zeros)\n",
    "padded = pad_sequences(sequences, maxlen=5)\n",
    "\n",
    "# Display the word index, sequences, and padded sequences\n",
    "print(\"\\nWord Index = \", word_index)\n",
    "print(\"\\nSequences = \", sequences)\n",
    "print(\"\\nPadded Sequences:\")\n",
    "print(padded)\n",
    "\n",
    "# Test data with new words that weren't in the original sentences\n",
    "test_data = [\n",
    "    'i really love my dog',\n",
    "    'my dog loves my manatee'\n",
    "]\n",
    "\n",
    "# Convert the test data into sequences based on the original tokenizer\n",
    "test_seq = tokenizer.texts_to_sequences(test_data)\n",
    "print(\"\\nTest Sequence = \", test_seq)\n",
    "\n",
    "# Pad the test sequences to a maximum length of 10\n",
    "padded_test_seq = pad_sequences(test_seq, maxlen=10)\n",
    "print(\"\\nPadded Test Sequence: \")\n",
    "print(padded_test_seq)\n"
   ],
   "id": "c8f60d239f85e690"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Now we got one final task, and that is to create a sarcasm detector: https://colab.research.google.com/github/lmoroney/dlaicourse/blob/master/TensorFlow%20In%20Practice/Course%203%20-%20NLP/Course%203%20-%20Week%201%20-%20Lesson%202.ipynb and here is the answer down here:\n",
   "id": "848c5d6dc9fb1f9f"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "import json\n",
    "\n",
    "# Load the dataset\n",
    "with open('sarcasm.json', 'r') as f:\n",
    "    data = json.load(f)\n",
    "\n",
    "# Extract sentences (headlines) and labels (sarcasm or not)\n",
    "sentences = [item['headline'] for item in data]\n",
    "labels = [item['is_sarcastic'] for item in data]\n",
    "\n",
    "# Tokenize the sentences\n",
    "tokenizer = Tokenizer(num_words=10000, oov_token=\"<OOV>\")\n",
    "tokenizer.fit_on_texts(sentences)\n",
    "word_index = tokenizer.word_index\n",
    "sequences = tokenizer.texts_to_sequences(sentences)\n",
    "\n",
    "# Pad the sequences\n",
    "padded = pad_sequences(sequences, padding='post', maxlen=100)\n",
    "\n",
    "# Split data into training and testing sets\n",
    "training_size = int(len(sentences) * 0.8)\n",
    "train_sentences = padded[:training_size]\n",
    "train_labels = labels[:training_size]\n",
    "test_sentences = padded[training_size:]\n",
    "test_labels = labels[training_size:]\n",
    "\n",
    "# Build the model\n",
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Embedding(10000, 16, input_length=100),  # Embedding layer for text input\n",
    "    tf.keras.layers.GlobalAveragePooling1D(),  # Reduces dimensions after embedding\n",
    "    tf.keras.layers.Dense(24, activation='relu'),  # Fully connected hidden layer\n",
    "    tf.keras.layers.Dense(1, activation='sigmoid')  # Output layer for binary classification\n",
    "])\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam',\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# Train the model\n",
    "history = model.fit(\n",
    "    train_sentences, train_labels,\n",
    "    epochs=10,\n",
    "    validation_data=(test_sentences, test_labels),\n",
    "    verbose=2\n",
    ")\n",
    "\n",
    "# Evaluate the model on test data\n",
    "test_loss, test_accuracy = model.evaluate(test_sentences, test_labels, verbose=2)\n",
    "print(f\"Test Accuracy: {test_accuracy}\")\n",
    "\n",
    "# Test with new sentences\n",
    "new_sentences = [\"The weather is amazing today!\", \"Oh great, another Monday.\"]\n",
    "new_sequences = tokenizer.texts_to_sequences(new_sentences)\n",
    "new_padded = pad_sequences(new_sequences, padding='post', maxlen=100)\n",
    "predictions = model.predict(new_padded)\n",
    "\n",
    "# Display predictions\n",
    "for i, sentence in enumerate(new_sentences):\n",
    "    print(f\"'{sentence}' -> Sarcasm score: {predictions[i][0]:.2f}\")\n"
   ],
   "id": "ede3b15a355b2902"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
