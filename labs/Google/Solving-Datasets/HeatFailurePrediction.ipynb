{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Model Explanation\n",
    "In this project, I’m leveraging advanced ensemble methods, specifically boosting algorithms like CatBoost, XGBoost, and LightGBM, combined into a stacking ensemble to predict heart failure outcomes with high accuracy. Boosting algorithms are particularly effective because they iteratively focus on the data points that are hardest to predict, which helps reduce errors and create a model that generalizes well. By combining these individual models in a stacking ensemble, I’m taking advantage of their unique strengths—CatBoost’s ability to handle categorical data, XGBoost’s speed and efficiency, and LightGBM’s capacity to handle large datasets—resulting in a model that’s not just accurate but also robust. To address the class imbalance in the data (e.g., fewer instances of heart failure), I used SMOTE, a synthetic oversampling technique, to balance the dataset and ensure the model treats both classes fairly. This approach works so well because it captures complex patterns in the data while mitigating overfitting, ultimately achieving a high accuracy of 92.68% and a stellar ROC-AUC of 98%, making it both predictive and reliable for real-world applications."
   ],
   "id": "121973627c767b68"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-10T12:09:35.539187Z",
     "start_time": "2025-03-10T12:09:34.805718Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import kagglehub\n",
    "import pandas as pd\n",
    "from catboost import CatBoostClassifier\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from lightgbm import LGBMClassifier\n",
    "from sklearn.ensemble import StackingClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report, roc_auc_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "print()\n",
    "# Download latest version\n",
    "path = kagglehub.dataset_download(\"andrewmvd/heart-failure-clinical-data\")\n",
    "print(\"Path to dataset files:\", path)\n",
    "\n",
    "# Load the dataset\n",
    "dataset_path = f\"{path}/heart_failure_clinical_records_dataset.csv\"\n",
    "data = pd.read_csv(dataset_path)\n",
    "\n",
    "# Display the first few rows\n",
    "print(data.head())\n",
    "\n",
    "# Separate features and target\n",
    "X = data.drop(columns=['DEATH_EVENT'])\n",
    "y = data['DEATH_EVENT']\n",
    "\n",
    "# Feature selection: Drop low-importance features (optional, depends on analysis)\n",
    "X = X.drop(columns=['smoking', 'anaemia', 'high_blood_pressure'])\n",
    "\n",
    "# Handle class imbalance using SMOTE\n",
    "smote = SMOTE(random_state=42)\n",
    "X_resampled, y_resampled = smote.fit_resample(X, y)\n",
    "\n",
    "# Split dataset into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X_resampled, y_resampled, test_size=0.2, random_state=42, stratify=y_resampled\n",
    ")\n",
    "\n",
    "# Initialize base models\n",
    "catboost_model = CatBoostClassifier(\n",
    "    iterations=500, learning_rate=0.1, depth=4, l2_leaf_reg=3, random_seed=42, verbose=0\n",
    ")\n",
    "xgb_model = XGBClassifier(\n",
    "    n_estimators=500, learning_rate=0.1, max_depth=4, reg_lambda=3, random_state=42, use_label_encoder=False,\n",
    "    eval_metric='logloss'\n",
    ")\n",
    "lgbm_model = LGBMClassifier(\n",
    "    n_estimators=500, learning_rate=0.1, max_depth=4, reg_lambda=3, random_state=42\n",
    ")\n",
    "\n",
    "# Initialize Stacking Classifier\n",
    "estimators = [\n",
    "    ('catboost', catboost_model),\n",
    "    ('xgb', xgb_model),\n",
    "    ('lgbm', lgbm_model),\n",
    "]\n",
    "stacking_model = StackingClassifier(\n",
    "    estimators=estimators,\n",
    "    final_estimator=CatBoostClassifier(\n",
    "        iterations=200, learning_rate=0.05, depth=6, random_seed=42, verbose=0\n",
    "    ),\n",
    "    cv=3,\n",
    "    passthrough=True\n",
    ")\n",
    "\n",
    "# Train the stacking model\n",
    "stacking_model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions\n",
    "y_pred = stacking_model.predict(X_test)\n",
    "y_pred_proba = stacking_model.predict_proba(X_test)[:, 1]\n",
    "\n",
    "# Evaluate the model\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "roc_auc = roc_auc_score(y_test, y_pred_proba)\n",
    "\n",
    "print(f\"Accuracy: {accuracy * 100:.2f}%\")\n",
    "print(f\"ROC-AUC: {roc_auc:.2f}\")\n",
    "\n",
    "# Print a detailed classification report\n",
    "print(\"\\nClassification Report:\\n\", classification_report(y_test, y_pred))\n"
   ],
   "id": "ad70d7d5155cff84",
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "numpy.dtype size changed, may indicate binary incompatibility. Expected 96 from C header, got 88 from PyObject",
     "output_type": "error",
     "traceback": [
      "\u001B[31m---------------------------------------------------------------------------\u001B[39m",
      "\u001B[31mValueError\u001B[39m                                Traceback (most recent call last)",
      "\u001B[36mCell\u001B[39m\u001B[36m \u001B[39m\u001B[32mIn[13]\u001B[39m\u001B[32m, line 3\u001B[39m\n\u001B[32m      1\u001B[39m \u001B[38;5;28;01mimport\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34;01mkagglehub\u001B[39;00m\n\u001B[32m      2\u001B[39m \u001B[38;5;28;01mimport\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34;01mpandas\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mas\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34;01mpd\u001B[39;00m\n\u001B[32m----> \u001B[39m\u001B[32m3\u001B[39m \u001B[38;5;28;01mfrom\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34;01mcatboost\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mimport\u001B[39;00m CatBoostClassifier\n\u001B[32m      4\u001B[39m \u001B[38;5;28;01mfrom\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34;01mimblearn\u001B[39;00m\u001B[34;01m.\u001B[39;00m\u001B[34;01mover_sampling\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mimport\u001B[39;00m SMOTE\n\u001B[32m      5\u001B[39m \u001B[38;5;28;01mfrom\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34;01mlightgbm\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mimport\u001B[39;00m LGBMClassifier\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/miniforge3/envs/ml/lib/python3.12/site-packages/catboost/__init__.py:1\u001B[39m\n\u001B[32m----> \u001B[39m\u001B[32m1\u001B[39m \u001B[38;5;28;01mfrom\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34;01m.\u001B[39;00m\u001B[34;01mcore\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mimport\u001B[39;00m (\n\u001B[32m      2\u001B[39m     FeaturesData, EFstrType, EShapCalcType, EFeaturesSelectionAlgorithm, EFeaturesSelectionGrouping,\n\u001B[32m      3\u001B[39m     Pool, CatBoost, CatBoostClassifier, CatBoostRegressor, CatBoostRanker, CatBoostError, cv, sample_gaussian_process, train,\n\u001B[32m      4\u001B[39m     sum_models, _have_equal_features, to_regressor, to_classifier, to_ranker, MultiRegressionCustomMetric,\n\u001B[32m      5\u001B[39m     MultiRegressionCustomObjective, MultiTargetCustomMetric, MultiTargetCustomObjective\n\u001B[32m      6\u001B[39m )  \u001B[38;5;66;03m# noqa\u001B[39;00m\n\u001B[32m      7\u001B[39m \u001B[38;5;28;01mfrom\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34;01m.\u001B[39;00m\u001B[34;01mversion\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mimport\u001B[39;00m VERSION \u001B[38;5;28;01mas\u001B[39;00m __version__  \u001B[38;5;66;03m# noqa\u001B[39;00m\n\u001B[32m      8\u001B[39m __all__ = [\n\u001B[32m      9\u001B[39m     \u001B[33m'\u001B[39m\u001B[33mFeaturesData\u001B[39m\u001B[33m'\u001B[39m, \u001B[33m'\u001B[39m\u001B[33mEFstrType\u001B[39m\u001B[33m'\u001B[39m, \u001B[33m'\u001B[39m\u001B[33mEShapCalcType\u001B[39m\u001B[33m'\u001B[39m, \u001B[33m'\u001B[39m\u001B[33mEFeaturesSelectionAlgorithm\u001B[39m\u001B[33m'\u001B[39m, \u001B[33m'\u001B[39m\u001B[33mEFeaturesSelectionGrouping\u001B[39m\u001B[33m'\u001B[39m,\n\u001B[32m     10\u001B[39m     \u001B[33m'\u001B[39m\u001B[33mPool\u001B[39m\u001B[33m'\u001B[39m, \u001B[33m'\u001B[39m\u001B[33mCatBoost\u001B[39m\u001B[33m'\u001B[39m, \u001B[33m'\u001B[39m\u001B[33mCatBoostClassifier\u001B[39m\u001B[33m'\u001B[39m, \u001B[33m'\u001B[39m\u001B[33mCatBoostRegressor\u001B[39m\u001B[33m'\u001B[39m, \u001B[33m'\u001B[39m\u001B[33mCatBoostRanker\u001B[39m\u001B[33m'\u001B[39m, \u001B[33m'\u001B[39m\u001B[33mCatboostError\u001B[39m\u001B[33m'\u001B[39m,\n\u001B[32m   (...)\u001B[39m\u001B[32m     13\u001B[39m     \u001B[33m'\u001B[39m\u001B[33mMultiTargetCustomMetric\u001B[39m\u001B[33m'\u001B[39m, \u001B[33m'\u001B[39m\u001B[33mMultiTargetCustomObjective\u001B[39m\u001B[33m'\u001B[39m\n\u001B[32m     14\u001B[39m ]\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/miniforge3/envs/ml/lib/python3.12/site-packages/catboost/core.py:45\u001B[39m\n\u001B[32m     40\u001B[39m         \u001B[38;5;28;01mpass\u001B[39;00m\n\u001B[32m     42\u001B[39m \u001B[38;5;28;01mimport\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34;01mscipy\u001B[39;00m\u001B[34;01m.\u001B[39;00m\u001B[34;01msparse\u001B[39;00m\n\u001B[32m---> \u001B[39m\u001B[32m45\u001B[39m \u001B[38;5;28;01mfrom\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34;01m.\u001B[39;00m\u001B[34;01mplot_helpers\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mimport\u001B[39;00m save_plot_file, try_plot_offline, OfflineMetricVisualizer\n\u001B[32m     46\u001B[39m \u001B[38;5;28;01mfrom\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34;01m.\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mimport\u001B[39;00m _catboost\n\u001B[32m     47\u001B[39m \u001B[38;5;28;01mfrom\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34;01m.\u001B[39;00m\u001B[34;01mmetrics\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mimport\u001B[39;00m BuiltinMetric\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/miniforge3/envs/ml/lib/python3.12/site-packages/catboost/plot_helpers.py:5\u001B[39m\n\u001B[32m      2\u001B[39m \u001B[38;5;28;01mimport\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34;01mos\u001B[39;00m\n\u001B[32m      3\u001B[39m \u001B[38;5;28;01mimport\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34;01mwarnings\u001B[39;00m\n\u001B[32m----> \u001B[39m\u001B[32m5\u001B[39m \u001B[38;5;28;01mfrom\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34;01m.\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mimport\u001B[39;00m _catboost\n\u001B[32m      6\u001B[39m fspath = _catboost.fspath\n\u001B[32m      9\u001B[39m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34mtry_plot_offline\u001B[39m(figs):\n",
      "\u001B[36mFile \u001B[39m\u001B[32m_catboost.pyx:1\u001B[39m, in \u001B[36minit _catboost\u001B[39m\u001B[34m()\u001B[39m\n",
      "\u001B[31mValueError\u001B[39m: numpy.dtype size changed, may indicate binary incompatibility. Expected 96 from C header, got 88 from PyObject"
     ]
    }
   ],
   "execution_count": 13
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
